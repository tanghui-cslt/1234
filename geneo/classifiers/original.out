nohup: ignoring input
Using TensorFlow backend.
  0%|          | 0/3 [00:00<?, ?it/s]
  0%|          | 0/3 [00:00<?, ?it/s][A2019-09-26 19:18:21,918 - knowledge_transfer - INFO - Working on dataset ./train_all_data/500_ops_20exs cifar10
WARNING: Logging before flag parsing goes to stderr.
I0926 19:18:21.918353 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/500_ops_20exs cifar10


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:18:21,918 - knowledge_transfer - INFO - Observer cifar10_21_cl_9_6.npy
I0926 19:18:21.918776 140696480909056 knowledge_transfer.py:94] Observer cifar10_21_cl_9_6.npy
2019-09-26 19:18:21,918 - knowledge_transfer - INFO - initialize data
I0926 19:18:21.918896 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 97/10000 [00:00<00:10, 966.72it/s][A[A[A


preprocessing train:   2%|â–         | 249/10000 [00:00<00:08, 1084.22it/s][A[A[A


preprocessing train:   4%|â–         | 423/10000 [00:00<00:07, 1221.23it/s][A[A[A


preprocessing train:   6%|â–Œ         | 599/10000 [00:00<00:06, 1344.41it/s][A[A[A


preprocessing train:   8%|â–Š         | 778/10000 [00:00<00:06, 1451.41it/s][A[A[A


preprocessing train:  10%|â–‰         | 957/10000 [00:00<00:05, 1538.15it/s][A[A[A


preprocessing train:  11%|â–ˆâ–        | 1137/10000 [00:00<00:05, 1608.08it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1316/10000 [00:00<00:05, 1656.72it/s][A[A[A


preprocessing train:  15%|â–ˆâ–        | 1495/10000 [00:00<00:05, 1693.43it/s][A[A[A


preprocessing train:  17%|â–ˆâ–‹        | 1675/10000 [00:01<00:04, 1722.34it/s][A[A[A


preprocessing train:  19%|â–ˆâ–Š        | 1855/10000 [00:01<00:04, 1742.57it/s][A[A[A


preprocessing train:  20%|â–ˆâ–ˆ        | 2035/10000 [00:01<00:04, 1757.56it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–       | 2215/10000 [00:01<00:04, 1767.72it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–       | 2392/10000 [00:01<00:04, 1734.83it/s][A[A[A


preprocessing train:  26%|â–ˆâ–ˆâ–Œ       | 2566/10000 [00:01<00:04, 1729.64it/s][A[A[A


preprocessing train:  27%|â–ˆâ–ˆâ–‹       | 2740/10000 [00:01<00:04, 1722.92it/s][A[A[A


preprocessing train:  29%|â–ˆâ–ˆâ–‰       | 2913/10000 [00:01<00:04, 1716.75it/s][A[A[A


preprocessing train:  31%|â–ˆâ–ˆâ–ˆ       | 3085/10000 [00:01<00:04, 1711.98it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3257/10000 [00:01<00:03, 1686.34it/s][A[A[A


preprocessing train:  34%|â–ˆâ–ˆâ–ˆâ–      | 3428/10000 [00:02<00:03, 1692.64it/s][A[A[A


preprocessing train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3599/10000 [00:02<00:03, 1695.65it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3771/10000 [00:02<00:03, 1700.75it/s][A[A[A


preprocessing train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3942/10000 [00:02<00:03, 1700.58it/s][A[A[A


preprocessing train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4113/10000 [00:02<00:03, 1702.03it/s][A[A[A


preprocessing train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4284/10000 [00:02<00:03, 1701.92it/s][A[A[A


preprocessing train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4455/10000 [00:02<00:03, 1697.30it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4625/10000 [00:02<00:03, 1696.82it/s][A[A[A


preprocessing train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4795/10000 [00:02<00:03, 1695.07it/s][A[A[A


preprocessing train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4965/10000 [00:02<00:02, 1693.67it/s][A[A[A


preprocessing train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5135/10000 [00:03<00:02, 1691.19it/s][A[A[A


preprocessing train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5305/10000 [00:03<00:02, 1691.24it/s][A[A[A


preprocessing train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5475/10000 [00:03<00:02, 1692.38it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5645/10000 [00:03<00:02, 1676.28it/s][A[A[A


preprocessing train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5813/10000 [00:03<00:02, 1676.84it/s][A[A[A


preprocessing train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5982/10000 [00:03<00:02, 1679.99it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6152/10000 [00:03<00:02, 1685.92it/s][A[A[A


preprocessing train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6322/10000 [00:03<00:02, 1689.33it/s][A[A[A


preprocessing train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6491/10000 [00:03<00:02, 1669.19it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6660/10000 [00:03<00:01, 1673.14it/s][A[A[A


preprocessing train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6829/10000 [00:04<00:01, 1675.20it/s][A[A[A


preprocessing train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6999/10000 [00:04<00:01, 1679.79it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7168/10000 [00:04<00:01, 1679.48it/s][A[A[A


preprocessing train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7336/10000 [00:04<00:01, 1678.83it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7505/10000 [00:04<00:01, 1681.91it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7675/10000 [00:04<00:01, 1686.54it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7845/10000 [00:04<00:01, 1688.05it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8015/10000 [00:04<00:01, 1690.54it/s][A[A[A


preprocessing train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8185/10000 [00:04<00:01, 1689.82it/s][A[A[A


preprocessing train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8354/10000 [00:04<00:00, 1652.65it/s][A[A[A


preprocessing train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8520/10000 [00:05<00:00, 1598.78it/s][A[A[A


preprocessing train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8681/10000 [00:05<00:00, 1567.46it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8839/10000 [00:05<00:00, 1545.49it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8994/10000 [00:05<00:00, 1532.00it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9148/10000 [00:05<00:00, 1526.13it/s][A[A[A


preprocessing train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9301/10000 [00:05<00:00, 1518.42it/s][A[A[A


preprocessing train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9454/10000 [00:05<00:00, 1512.47it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9606/10000 [00:05<00:00, 1455.67it/s][A[A[A


preprocessing train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9766/10000 [00:05<00:00, 1495.19it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9917/10000 [00:05<00:00, 1494.80it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1651.91it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   7%|â–‹         | 149/2000 [00:00<00:01, 1485.62it/s][A[A[A


preprocessing test:  15%|â–ˆâ–        | 299/2000 [00:00<00:01, 1489.73it/s][A[A[A


preprocessing test:  22%|â–ˆâ–ˆâ–       | 449/2000 [00:00<00:01, 1492.07it/s][A[A[A


preprocessing test:  30%|â–ˆâ–ˆâ–‰       | 599/2000 [00:00<00:00, 1494.27it/s][A[A[A


preprocessing test:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 749/2000 [00:00<00:00, 1495.92it/s][A[A[A


preprocessing test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 898/2000 [00:00<00:00, 1493.81it/s][A[A[A


preprocessing test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1048/2000 [00:00<00:00, 1492.84it/s][A[A[A


preprocessing test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1198/2000 [00:00<00:00, 1493.03it/s][A[A[A


preprocessing test:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1355/2000 [00:00<00:00, 1513.60it/s][A[A[A


preprocessing test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1504/2000 [00:01<00:00, 1505.87it/s][A[A[A


preprocessing test:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1653/2000 [00:01<00:00, 1500.97it/s][A[A[A


preprocessing test:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1803/2000 [00:01<00:00, 1498.34it/s][A[A[A


preprocessing test:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1953/2000 [00:01<00:00, 1495.84it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1498.22it/s]
2019-09-26 19:18:29,872 - knowledge_transfer - INFO - test with geneo init
I0926 19:18:29.872182 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:18:30,028 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:18:30.028113 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:18:30,071 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:18:30.071865 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
W0926 19:18:30.085570 140696480909056 deprecation_wrapper.py:119] From /home/tmp/dingwei/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

2019-09-26 19:18:30.367890: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-09-26 19:18:30.401201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2195050000 Hz
2019-09-26 19:18:30.403867: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56463f9a6980 executing computations on platform Host. Devices:
2019-09-26 19:18:30.403904: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-09-26 19:18:30.405916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-26 19:18:32.384247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
2019-09-26 19:18:32.385078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
2019-09-26 19:18:32.385815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:81:00.0
2019-09-26 19:18:32.386090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-26 19:18:32.387228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-26 19:18:32.388306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-26 19:18:32.388586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-26 19:18:32.389896: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-26 19:18:32.390916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-26 19:18:32.394232: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-26 19:18:32.398488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2
2019-09-26 19:18:32.398533: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-26 19:18:32.401438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-26 19:18:32.401457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 
2019-09-26 19:18:32.401466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N 
2019-09-26 19:18:32.401472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N 
2019-09-26 19:18:32.401478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N 
2019-09-26 19:18:32.405119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
2019-09-26 19:18:32.406949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10481 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
2019-09-26 19:18:32.408640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10481 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)
2019-09-26 19:18:32.411109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564641373600 executing computations on platform CUDA. Devices:
2019-09-26 19:18:32.411130: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-26 19:18:32.411138: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-09-26 19:18:32.411144: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1
W0926 19:18:33.452624 140696480909056 deprecation_wrapper.py:119] From /home/tmp/dingwei/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2019-09-26 19:18:33.619088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-26 19:18:33.934940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-26 19:19:17,136 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:19:17.136561 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:19:17,137 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:19:17.137143 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [9, 6] 
conv2d_1
True
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 186624)            0         
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00012: early stopping
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2 (Conv2D)            (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 186624)            0         
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 2.9958 - accuracy: 0.6540 - val_loss: 0.5704 - val_accuracy: 0.6727
Epoch 2/100
 - 3s - loss: 0.5283 - accuracy: 0.7403 - val_loss: 0.5370 - val_accuracy: 0.7597
Epoch 3/100
 - 3s - loss: 0.4778 - accuracy: 0.7884 - val_loss: 0.4925 - val_accuracy: 0.7823
Epoch 4/100
 - 3s - loss: 0.4301 - accuracy: 0.8084 - val_loss: 0.5002 - val_accuracy: 0.7753
Epoch 5/100
 - 3s - loss: 0.3609 - accuracy: 0.8443 - val_loss: 0.5341 - val_accuracy: 0.8333
Epoch 6/100
 - 3s - loss: 0.3149 - accuracy: 0.8649 - val_loss: 0.4738 - val_accuracy: 0.8347
Epoch 7/100
 - 3s - loss: 0.2552 - accuracy: 0.8944 - val_loss: 0.4419 - val_accuracy: 0.8593
Epoch 8/100
 - 4s - loss: 0.2280 - accuracy: 0.9039 - val_loss: 0.5283 - val_accuracy: 0.8263
Epoch 9/100
 - 4s - loss: 0.2389 - accuracy: 0.9070 - val_loss: 0.6004 - val_accuracy: 0.7823
Epoch 10/100
 - 4s - loss: 0.1942 - accuracy: 0.9190 - val_loss: 0.6946 - val_accuracy: 0.8147
Epoch 11/100
 - 4s - loss: 0.2023 - accuracy: 0.9223 - val_loss: 0.6475 - val_accuracy: 0.7500
Epoch 12/100
 - 4s - loss: 0.3210 - accuracy: 0.8714 - val_loss: 0.6492 - val_accuracy: 0.8023


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:38<03:16, 98.20s/it][A[A2019-09-26 19:20:00,121 - knowledge_transfer - INFO - Observer cifar10_7_cl_9_6.npy
I0926 19:20:00.121663 140696480909056 knowledge_transfer.py:94] Observer cifar10_7_cl_9_6.npy
2019-09-26 19:20:00,122 - knowledge_transfer - INFO - initialize data
I0926 19:20:00.122066 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 54/10000 [00:00<00:18, 538.87it/s][A[A[A


preprocessing train:   2%|â–         | 200/10000 [00:00<00:14, 664.67it/s][A[A[A


preprocessing train:   4%|â–Ž         | 374/10000 [00:00<00:11, 815.31it/s][A[A[A


preprocessing train:   5%|â–Œ         | 533/10000 [00:00<00:09, 953.99it/s][A[A[A


preprocessing train:   7%|â–‹         | 692/10000 [00:00<00:08, 1083.20it/s][A[A[A


preprocessing train:   9%|â–Š         | 851/10000 [00:00<00:07, 1197.19it/s][A[A[A


preprocessing train:  10%|â–ˆ         | 1041/10000 [00:00<00:06, 1345.81it/s][A[A[A


preprocessing train:  12%|â–ˆâ–        | 1231/10000 [00:00<00:05, 1473.71it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1421/10000 [00:00<00:05, 1578.72it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1610/10000 [00:01<00:05, 1660.33it/s][A[A[A


preprocessing train:  18%|â–ˆâ–Š        | 1799/10000 [00:01<00:04, 1721.40it/s][A[A[A


preprocessing train:  20%|â–ˆâ–‰        | 1987/10000 [00:01<00:04, 1763.61it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–       | 2175/10000 [00:01<00:04, 1794.79it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–Ž       | 2363/10000 [00:01<00:04, 1816.86it/s][A[A[A


preprocessing train:  26%|â–ˆâ–ˆâ–Œ       | 2551/10000 [00:01<00:04, 1833.95it/s][A[A[A


preprocessing train:  27%|â–ˆâ–ˆâ–‹       | 2740/10000 [00:01<00:03, 1849.62it/s][A[A[A


preprocessing train:  29%|â–ˆâ–ˆâ–‰       | 2929/10000 [00:01<00:03, 1859.90it/s][A[A[A


preprocessing train:  31%|â–ˆâ–ˆâ–ˆ       | 3117/10000 [00:01<00:03, 1861.52it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3304/10000 [00:01<00:03, 1856.08it/s][A[A[A


preprocessing train:  35%|â–ˆâ–ˆâ–ˆâ–      | 3491/10000 [00:02<00:03, 1852.82it/s][A[A[A


preprocessing train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3677/10000 [00:02<00:03, 1819.44it/s][A[A[A


preprocessing train:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 3860/10000 [00:02<00:03, 1735.21it/s][A[A[A


preprocessing train:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4035/10000 [00:02<00:03, 1678.86it/s][A[A[A


preprocessing train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4205/10000 [00:02<00:03, 1648.21it/s][A[A[A


preprocessing train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4389/10000 [00:02<00:03, 1700.42it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4571/10000 [00:02<00:03, 1731.35it/s][A[A[A


preprocessing train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4746/10000 [00:02<00:03, 1678.59it/s][A[A[A


preprocessing train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4915/10000 [00:02<00:03, 1645.42it/s][A[A[A


preprocessing train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5081/10000 [00:02<00:03, 1621.90it/s][A[A[A


preprocessing train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5244/10000 [00:03<00:02, 1605.88it/s][A[A[A


preprocessing train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5406/10000 [00:03<00:02, 1595.63it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5575/10000 [00:03<00:02, 1621.25it/s][A[A[A


preprocessing train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5744/10000 [00:03<00:02, 1640.59it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5909/10000 [00:03<00:02, 1621.84it/s][A[A[A


preprocessing train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6072/10000 [00:03<00:02, 1614.73it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6234/10000 [00:03<00:02, 1612.94it/s][A[A[A


preprocessing train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6396/10000 [00:03<00:02, 1605.98it/s][A[A[A


preprocessing train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6557/10000 [00:03<00:02, 1602.93it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6718/10000 [00:03<00:02, 1599.14it/s][A[A[A


preprocessing train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6878/10000 [00:04<00:01, 1591.54it/s][A[A[A


preprocessing train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7038/10000 [00:04<00:01, 1588.48it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7197/10000 [00:04<00:01, 1586.59it/s][A[A[A


preprocessing train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7356/10000 [00:04<00:01, 1467.77it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7523/10000 [00:04<00:01, 1522.36it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7689/10000 [00:04<00:01, 1560.58it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7847/10000 [00:04<00:01, 1538.36it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8002/10000 [00:04<00:01, 1523.48it/s][A[A[A


preprocessing train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8156/10000 [00:04<00:01, 1507.26it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8308/10000 [00:05<00:01, 1502.25it/s][A[A[A


preprocessing train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8459/10000 [00:05<00:01, 1500.58it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8620/10000 [00:05<00:00, 1530.19it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8791/10000 [00:05<00:00, 1578.20it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8962/10000 [00:05<00:00, 1613.52it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9127/10000 [00:05<00:00, 1621.52it/s][A[A[A


preprocessing train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9290/10000 [00:05<00:00, 1580.46it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9449/10000 [00:05<00:00, 1556.77it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9606/10000 [00:05<00:00, 1540.45it/s][A[A[A


preprocessing train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9761/10000 [00:05<00:00, 1529.78it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9915/10000 [00:06<00:00, 1523.37it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1631.96it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   8%|â–Š         | 166/2000 [00:00<00:01, 1653.41it/s][A[A[A


preprocessing test:  17%|â–ˆâ–‹        | 334/2000 [00:00<00:01, 1660.68it/s][A[A[A


preprocessing test:  25%|â–ˆâ–ˆâ–       | 496/2000 [00:00<00:00, 1645.50it/s][A[A[A


preprocessing test:  32%|â–ˆâ–ˆâ–ˆâ–      | 646/2000 [00:00<00:00, 1598.45it/s][A[A[A


preprocessing test:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 796/2000 [00:00<00:00, 1566.59it/s][A[A[A


preprocessing test:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 946/2000 [00:00<00:00, 1545.06it/s][A[A[A


preprocessing test:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1097/2000 [00:00<00:00, 1533.36it/s][A[A[A


preprocessing test:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1246/2000 [00:00<00:00, 1517.25it/s][A[A[A


preprocessing test:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1389/2000 [00:00<00:00, 1481.91it/s][A[A[A


preprocessing test:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1536/2000 [00:01<00:00, 1476.76it/s][A[A[A


preprocessing test:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1684/2000 [00:01<00:00, 1475.27it/s][A[A[A


preprocessing test:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1832/2000 [00:01<00:00, 1474.09it/s][A[A[A


preprocessing test:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1980/2000 [00:01<00:00, 1473.08it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1514.89it/s]
2019-09-26 19:20:08,023 - knowledge_transfer - INFO - test with geneo init
I0926 19:20:08.023789 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:20:08,073 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:20:08.073746 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:20:08,098 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:20:08.098433 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:20:44,372 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:20:44.372259 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:20:44,372 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:20:44.372890 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00012: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [9, 6] 
conv2d_3
True
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_3 (Conv2D)            (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 238144)            0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00011: early stopping
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 238144)            0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 3s - loss: 5.9024 - accuracy: 0.7561 - val_loss: 0.9643 - val_accuracy: 0.8113
Epoch 2/100
 - 3s - loss: 0.4584 - accuracy: 0.8796 - val_loss: 0.5646 - val_accuracy: 0.8503
Epoch 3/100
 - 3s - loss: 0.2066 - accuracy: 0.9296 - val_loss: 0.5919 - val_accuracy: 0.8477
Epoch 4/100
 - 3s - loss: 0.0979 - accuracy: 0.9626 - val_loss: 0.3726 - val_accuracy: 0.8940
Epoch 5/100
 - 3s - loss: 0.0548 - accuracy: 0.9801 - val_loss: 0.3830 - val_accuracy: 0.8957
Epoch 6/100
 - 3s - loss: 0.0488 - accuracy: 0.9829 - val_loss: 0.3778 - val_accuracy: 0.8890
Epoch 7/100
 - 3s - loss: 0.0350 - accuracy: 0.9880 - val_loss: 0.8072 - val_accuracy: 0.8287
Epoch 8/100
 - 3s - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.4440 - val_accuracy: 0.8903
Epoch 9/100
 - 3s - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.4430 - val_accuracy: 0.8963
Epoch 10/100
 - 3s - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.4460 - val_accuracy: 0.8997
Epoch 11/100
 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9060
Epoch 12/100
 - 3s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9047
Epoch 13/100
 - 3s - loss: 9.1502e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9053
Epoch 14/100
 - 3s - loss: 7.9887e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9047
Epoch 15/100
 - 3s - loss: 6.6114e-04 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9083
Epoch 16/100
 - 3s - loss: 5.5655e-04 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9067
Epoch 17/100
 - 3s - loss: 4.9648e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9063
Epoch 18/100
 - 3s - loss: 4.0985e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9063
Epoch 19/100
 - 3s - loss: 3.6208e-04 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9087
Epoch 20/100
 - 3s - loss: 3.5472e-04 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9077
Epoch 21/100
 - 3s - loss: 2.7923e-04 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9070
Epoch 22/100
 - 3s - loss: 2.4274e-04 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9077
Epoch 23/100
 - 3s - loss: 2.2341e-04 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9090
Epoch 24/100
 - 3s - loss: 1.8242e-04 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9080
Epoch 25/100
 - 3s - loss: 1.7429e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9090
Epoch 26/100
 - 3s - loss: 1.3952e-04 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9090
Epoch 27/100
 - 3s - loss: 1.2549e-04 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9103
Epoch 28/100
 - 3s - loss: 1.1787e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9083
Epoch 29/100
 - 3s - loss: 9.6574e-05 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9073
Epoch 30/100
 - 3s - loss: 8.9848e-05 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9090
Epoch 31/100
 - 3s - loss: 7.8255e-05 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9077
Epoch 32/100
 - 3s - loss: 7.0202e-05 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.9053


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [04:08<01:53, 113.69s/it][A[A2019-09-26 19:22:29,940 - knowledge_transfer - INFO - Observer cifar10_11_cl_9_6.npy
I0926 19:22:29.940890 140696480909056 knowledge_transfer.py:94] Observer cifar10_11_cl_9_6.npy
2019-09-26 19:22:29,941 - knowledge_transfer - INFO - initialize data
I0926 19:22:29.941162 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 72/10000 [00:00<00:13, 718.37it/s][A[A[A


preprocessing train:   2%|â–         | 178/10000 [00:00<00:12, 795.02it/s][A[A[A


preprocessing train:   4%|â–Ž         | 356/10000 [00:00<00:10, 952.63it/s][A[A[A


preprocessing train:   5%|â–Œ         | 533/10000 [00:00<00:08, 1105.02it/s][A[A[A


preprocessing train:   7%|â–‹         | 712/10000 [00:00<00:07, 1246.88it/s][A[A[A


preprocessing train:   9%|â–‰         | 893/10000 [00:00<00:06, 1373.58it/s][A[A[A


preprocessing train:  11%|â–ˆ         | 1073/10000 [00:00<00:06, 1477.41it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1253/10000 [00:00<00:05, 1561.11it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1417/10000 [00:00<00:05, 1573.91it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1580/10000 [00:01<00:05, 1581.72it/s][A[A[A


preprocessing train:  17%|â–ˆâ–‹        | 1742/10000 [00:01<00:05, 1591.35it/s][A[A[A


preprocessing train:  19%|â–ˆâ–‰        | 1904/10000 [00:01<00:05, 1593.04it/s][A[A[A


preprocessing train:  21%|â–ˆâ–ˆ        | 2066/10000 [00:01<00:04, 1596.71it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–       | 2227/10000 [00:01<00:04, 1598.82it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–       | 2388/10000 [00:01<00:04, 1599.39it/s][A[A[A


preprocessing train:  25%|â–ˆâ–ˆâ–Œ       | 2549/10000 [00:01<00:04, 1600.61it/s][A[A[A


preprocessing train:  27%|â–ˆâ–ˆâ–‹       | 2710/10000 [00:01<00:04, 1601.59it/s][A[A[A


preprocessing train:  29%|â–ˆâ–ˆâ–Š       | 2871/10000 [00:01<00:04, 1600.86it/s][A[A[A


preprocessing train:  30%|â–ˆâ–ˆâ–ˆ       | 3032/10000 [00:01<00:04, 1598.44it/s][A[A[A


preprocessing train:  32%|â–ˆâ–ˆâ–ˆâ–      | 3192/10000 [00:02<00:04, 1598.21it/s][A[A[A


preprocessing train:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 3352/10000 [00:02<00:04, 1595.55it/s][A[A[A


preprocessing train:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 3513/10000 [00:02<00:04, 1596.95it/s][A[A[A


preprocessing train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3674/10000 [00:02<00:03, 1598.59it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3834/10000 [00:02<00:03, 1597.69it/s][A[A[A


preprocessing train:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3994/10000 [00:02<00:03, 1598.13it/s][A[A[A


preprocessing train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4154/10000 [00:02<00:03, 1597.64it/s][A[A[A


preprocessing train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4314/10000 [00:02<00:03, 1593.51it/s][A[A[A


preprocessing train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4474/10000 [00:02<00:03, 1589.11it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4633/10000 [00:02<00:03, 1585.76it/s][A[A[A


preprocessing train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4792/10000 [00:03<00:03, 1583.10it/s][A[A[A


preprocessing train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4951/10000 [00:03<00:03, 1581.75it/s][A[A[A


preprocessing train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5110/10000 [00:03<00:03, 1579.15it/s][A[A[A


preprocessing train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5268/10000 [00:03<00:02, 1578.70it/s][A[A[A


preprocessing train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5429/10000 [00:03<00:02, 1585.42it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5588/10000 [00:03<00:02, 1582.30it/s][A[A[A


preprocessing train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5747/10000 [00:03<00:02, 1579.33it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5905/10000 [00:03<00:02, 1577.46it/s][A[A[A


preprocessing train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6063/10000 [00:03<00:02, 1572.84it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6221/10000 [00:03<00:02, 1572.47it/s][A[A[A


preprocessing train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6379/10000 [00:04<00:02, 1568.66it/s][A[A[A


preprocessing train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6536/10000 [00:04<00:02, 1562.45it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6698/10000 [00:04<00:02, 1578.97it/s][A[A[A


preprocessing train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6857/10000 [00:04<00:01, 1580.49it/s][A[A[A


preprocessing train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7016/10000 [00:04<00:01, 1581.79it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7175/10000 [00:04<00:01, 1578.91it/s][A[A[A


preprocessing train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7335/10000 [00:04<00:01, 1582.92it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7494/10000 [00:04<00:01, 1583.04it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7653/10000 [00:04<00:01, 1580.59it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7812/10000 [00:04<00:01, 1579.82it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7970/10000 [00:05<00:01, 1579.65it/s][A[A[A


preprocessing train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8128/10000 [00:05<00:01, 1570.65it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8295/10000 [00:05<00:01, 1599.06it/s][A[A[A


preprocessing train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8458/10000 [00:05<00:00, 1607.75it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8621/10000 [00:05<00:00, 1612.26it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8792/10000 [00:05<00:00, 1638.37it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8977/10000 [00:05<00:00, 1695.89it/s][A[A[A


preprocessing train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9154/10000 [00:05<00:00, 1716.46it/s][A[A[A


preprocessing train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9331/10000 [00:05<00:00, 1729.85it/s][A[A[A


preprocessing train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9505/10000 [00:05<00:00, 1716.12it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9677/10000 [00:06<00:00, 1671.80it/s][A[A[A


preprocessing train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9845/10000 [00:06<00:00, 1618.36it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1597.54it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   8%|â–Š         | 158/2000 [00:00<00:01, 1572.25it/s][A[A[A


preprocessing test:  16%|â–ˆâ–Œ        | 317/2000 [00:00<00:01, 1577.51it/s][A[A[A


preprocessing test:  24%|â–ˆâ–ˆâ–       | 477/2000 [00:00<00:00, 1583.81it/s][A[A[A


preprocessing test:  32%|â–ˆâ–ˆâ–ˆâ–      | 637/2000 [00:00<00:00, 1587.75it/s][A[A[A


preprocessing test:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 797/2000 [00:00<00:00, 1589.33it/s][A[A[A


preprocessing test:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 957/2000 [00:00<00:00, 1589.73it/s][A[A[A


preprocessing test:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1117/2000 [00:00<00:00, 1590.38it/s][A[A[A


preprocessing test:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1278/2000 [00:00<00:00, 1593.29it/s][A[A[A


preprocessing test:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1438/2000 [00:00<00:00, 1594.03it/s][A[A[A


preprocessing test:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1617/2000 [00:01<00:00, 1646.53it/s][A[A[A


preprocessing test:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1797/2000 [00:01<00:00, 1687.60it/s][A[A[A


preprocessing test:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1964/2000 [00:01<00:00, 1680.03it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1629.81it/s]
2019-09-26 19:22:37,693 - knowledge_transfer - INFO - test with geneo init
I0926 19:22:37.693308 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:22:37,740 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:22:37.740773 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:22:37,764 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:22:37.764071 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:23:10,940 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:23:10.940596 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:23:10,941 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:23:10.941041 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00032: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [9, 6] 
conv2d_5
True
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 222784)            0         
_________________________________________________________________
dense_5 (Dense)              (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00010: early stopping
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 222784)            0         
_________________________________________________________________
dense_6 (Dense)              (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 3s - loss: 4.1459 - accuracy: 0.7654 - val_loss: 0.3668 - val_accuracy: 0.8530
Epoch 2/100
 - 3s - loss: 0.2408 - accuracy: 0.9077 - val_loss: 0.3289 - val_accuracy: 0.8777
Epoch 3/100
 - 3s - loss: 0.1588 - accuracy: 0.9387 - val_loss: 0.3052 - val_accuracy: 0.8937
Epoch 4/100
 - 3s - loss: 0.1239 - accuracy: 0.9529 - val_loss: 0.4543 - val_accuracy: 0.8453
Epoch 5/100
 - 3s - loss: 0.0818 - accuracy: 0.9696 - val_loss: 0.4697 - val_accuracy: 0.8730
Epoch 6/100
 - 3s - loss: 0.0396 - accuracy: 0.9871 - val_loss: 0.3538 - val_accuracy: 0.9047
Epoch 7/100
 - 3s - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.4205 - val_accuracy: 0.8890
Epoch 8/100
 - 3s - loss: 0.0451 - accuracy: 0.9854 - val_loss: 0.4323 - val_accuracy: 0.8900
Epoch 9/100
 - 3s - loss: 0.0415 - accuracy: 0.9847 - val_loss: 0.4348 - val_accuracy: 0.8970
Epoch 10/100
 - 3s - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.5073 - val_accuracy: 0.8810
Epoch 11/100
 - 3s - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.5213 - val_accuracy: 0.8867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [05:26<00:00, 103.09s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [05:26<00:00, 108.79s/it]

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [05:26<10:52, 326.38s/it][A2019-09-26 19:23:48,293 - knowledge_transfer - INFO - Working on dataset ./train_all_data/500_ops_20exs fashion_mnist
I0926 19:23:48.293889 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/500_ops_20exs fashion_mnist


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:23:48,294 - knowledge_transfer - INFO - Observer fashion_mnist_7_cl_7_0.npy
I0926 19:23:48.294642 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_7_cl_7_0.npy
2019-09-26 19:23:48,294 - knowledge_transfer - INFO - data already initialised
I0926 19:23:48.294783 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:23:48,310 - knowledge_transfer - INFO - test with geneo init
I0926 19:23:48.310085 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:23:48,361 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:23:48.361233 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:23:48,386 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:23:48.386367 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:24:58,512 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:24:58.512174 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:24:58,512 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:24:58.512763 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00011: early stopping
conv2d_7
True
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 238144)            0         
_________________________________________________________________
dense_7 (Dense)              (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00021: early stopping
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 238144)            0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 7.6864 - accuracy: 0.7521 - val_loss: 0.5157 - val_accuracy: 0.8337
Epoch 2/100
 - 3s - loss: 0.3670 - accuracy: 0.8837 - val_loss: 0.4335 - val_accuracy: 0.8550
Epoch 3/100
 - 3s - loss: 0.1778 - accuracy: 0.9324 - val_loss: 0.6499 - val_accuracy: 0.8170
Epoch 4/100
 - 3s - loss: 0.1044 - accuracy: 0.9600 - val_loss: 0.3744 - val_accuracy: 0.8790
Epoch 5/100
 - 3s - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.3301 - val_accuracy: 0.8963
Epoch 6/100
 - 3s - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.3519 - val_accuracy: 0.9003
Epoch 7/100
 - 3s - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.4283 - val_accuracy: 0.8807
Epoch 8/100
 - 3s - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.3342 - val_accuracy: 0.9057
Epoch 9/100
 - 3s - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.3898 - val_accuracy: 0.8977
Epoch 10/100
 - 3s - loss: 0.0483 - accuracy: 0.9837 - val_loss: 0.4346 - val_accuracy: 0.8787
Epoch 11/100
 - 3s - loss: 0.0534 - accuracy: 0.9796 - val_loss: 0.5279 - val_accuracy: 0.8747
Epoch 12/100
 - 3s - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.5404 - val_accuracy: 0.8800
Epoch 13/100
 - 3s - loss: 0.0275 - accuracy: 0.9904 - val_loss: 0.4590 - val_accuracy: 0.8907


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:54<03:49, 114.55s/it][A[A2019-09-26 19:25:42,846 - knowledge_transfer - INFO - Observer fashion_mnist_11_cl_7_0.npy
I0926 19:25:42.846608 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_11_cl_7_0.npy
2019-09-26 19:25:42,847 - knowledge_transfer - INFO - data already initialised
I0926 19:25:42.847043 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:25:42,866 - knowledge_transfer - INFO - test with geneo init
I0926 19:25:42.866181 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:25:42,916 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:25:42.916760 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:25:42,941 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:25:42.941903 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:26:23,533 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:26:23.533736 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:26:23,534 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:26:23.534340 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00013: early stopping
conv2d_9
True
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 222784)            0         
_________________________________________________________________
dense_9 (Dense)              (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00012: early stopping
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_10 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 3s - loss: 4.5976 - accuracy: 0.7871 - val_loss: 0.3414 - val_accuracy: 0.8703
Epoch 2/100
 - 3s - loss: 0.2596 - accuracy: 0.8974 - val_loss: 0.4694 - val_accuracy: 0.8233
Epoch 3/100
 - 3s - loss: 0.1580 - accuracy: 0.9379 - val_loss: 0.3044 - val_accuracy: 0.8913
Epoch 4/100
 - 3s - loss: 0.0968 - accuracy: 0.9631 - val_loss: 0.3284 - val_accuracy: 0.8967
Epoch 5/100
 - 3s - loss: 0.0757 - accuracy: 0.9706 - val_loss: 0.4036 - val_accuracy: 0.8760
Epoch 6/100
 - 3s - loss: 0.0742 - accuracy: 0.9717 - val_loss: 0.3447 - val_accuracy: 0.8953
Epoch 7/100
 - 3s - loss: 0.0411 - accuracy: 0.9876 - val_loss: 0.4529 - val_accuracy: 0.8867
Epoch 8/100
 - 3s - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.4178 - val_accuracy: 0.8953
Epoch 9/100
 - 3s - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.5009 - val_accuracy: 0.8770


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [03:05<01:41, 101.62s/it][A[A2019-09-26 19:26:54,292 - knowledge_transfer - INFO - Observer fashion_mnist_21_cl_7_0.npy
I0926 19:26:54.292362 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_21_cl_7_0.npy
2019-09-26 19:26:54,292 - knowledge_transfer - INFO - data already initialised
I0926 19:26:54.292801 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:26:54,327 - knowledge_transfer - INFO - test with geneo init
I0926 19:26:54.327575 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:26:54,380 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:26:54.380693 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:26:54,406 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:26:54.406853 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:27:33,156 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:27:33.156508 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:27:33,157 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:27:33.157140 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00009: early stopping
conv2d_11
True
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_11 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00010: early stopping
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_12 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 3.2890 - accuracy: 0.6573 - val_loss: 0.5721 - val_accuracy: 0.7270
Epoch 2/100
 - 4s - loss: 0.4979 - accuracy: 0.7671 - val_loss: 0.5801 - val_accuracy: 0.7077
Epoch 3/100
 - 4s - loss: 0.4182 - accuracy: 0.8174 - val_loss: 0.5366 - val_accuracy: 0.7657
Epoch 4/100
 - 4s - loss: 0.3699 - accuracy: 0.8419 - val_loss: 0.5551 - val_accuracy: 0.7967
Epoch 5/100
 - 4s - loss: 0.3109 - accuracy: 0.8709 - val_loss: 0.4795 - val_accuracy: 0.8177
Epoch 6/100
 - 4s - loss: 0.2924 - accuracy: 0.8747 - val_loss: 0.6295 - val_accuracy: 0.7783
Epoch 7/100
 - 4s - loss: 0.2572 - accuracy: 0.8937 - val_loss: 0.5046 - val_accuracy: 0.8300
Epoch 8/100
 - 4s - loss: 0.2138 - accuracy: 0.9151 - val_loss: 0.6812 - val_accuracy: 0.7977
Epoch 9/100
 - 4s - loss: 0.1882 - accuracy: 0.9247 - val_loss: 0.5173 - val_accuracy: 0.8513
Epoch 10/100
 - 4s - loss: 0.1901 - accuracy: 0.9234 - val_loss: 0.7503 - val_accuracy: 0.8067
Epoch 11/100
 - 4s - loss: 0.1540 - accuracy: 0.9403 - val_loss: 0.5031 - val_accuracy: 0.8593
Epoch 12/100
 - 4s - loss: 0.1424 - accuracy: 0.9449 - val_loss: 0.6802 - val_accuracy: 0.8360
Epoch 13/100
 - 4s - loss: 0.1223 - accuracy: 0.9523 - val_loss: 0.6825 - val_accuracy: 0.8263
Epoch 14/100
 - 4s - loss: 0.1027 - accuracy: 0.9579 - val_loss: 0.6719 - val_accuracy: 0.8447
Epoch 15/100
 - 4s - loss: 0.1054 - accuracy: 0.9591 - val_loss: 0.8009 - val_accuracy: 0.8333
Epoch 16/100
 - 4s - loss: 0.1189 - accuracy: 0.9529 - val_loss: 0.7180 - val_accuracy: 0.8397


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:46<00:00, 101.14s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:46<00:00, 95.34s/it] 

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [10:12<05:14, 314.27s/it][A2019-09-26 19:28:34,323 - knowledge_transfer - INFO - Working on dataset ./train_all_data/500_ops_20exs mnist
I0926 19:28:34.323659 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/500_ops_20exs mnist


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:28:34,324 - knowledge_transfer - INFO - Observer mnist_7_cl_7_5.npy
I0926 19:28:34.324333 140696480909056 knowledge_transfer.py:94] Observer mnist_7_cl_7_5.npy
2019-09-26 19:28:34,324 - knowledge_transfer - INFO - data already initialised
I0926 19:28:34.324463 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:28:34,339 - knowledge_transfer - INFO - test with geneo init
I0926 19:28:34.339951 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:28:34,387 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:28:34.387088 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:28:34,410 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:28:34.410581 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:29:09,041 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:29:09.041558 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:29:09,042 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:29:09.042082 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00016: early stopping
conv2d_13
True
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_13 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00010: early stopping
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_14 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_14 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 8.6036 - accuracy: 0.7513 - val_loss: 1.9046 - val_accuracy: 0.7793
Epoch 2/100
 - 3s - loss: 0.6609 - accuracy: 0.8733 - val_loss: 0.6891 - val_accuracy: 0.8637
Epoch 3/100
 - 3s - loss: 0.3043 - accuracy: 0.9196 - val_loss: 0.5271 - val_accuracy: 0.8837
Epoch 4/100
 - 3s - loss: 0.1516 - accuracy: 0.9483 - val_loss: 0.5281 - val_accuracy: 0.8790
Epoch 5/100
 - 3s - loss: 0.0838 - accuracy: 0.9686 - val_loss: 0.5434 - val_accuracy: 0.8793
Epoch 6/100
 - 3s - loss: 0.0596 - accuracy: 0.9763 - val_loss: 0.4919 - val_accuracy: 0.8913
Epoch 7/100
 - 3s - loss: 0.0466 - accuracy: 0.9839 - val_loss: 0.4938 - val_accuracy: 0.8880
Epoch 8/100
 - 3s - loss: 0.0258 - accuracy: 0.9893 - val_loss: 0.5942 - val_accuracy: 0.8783
Epoch 9/100
 - 3s - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.4874 - val_accuracy: 0.8977
Epoch 10/100
 - 3s - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.5771 - val_accuracy: 0.8757
Epoch 11/100
 - 3s - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.5678 - val_accuracy: 0.8893
Epoch 12/100
 - 3s - loss: 0.0618 - accuracy: 0.9779 - val_loss: 0.9092 - val_accuracy: 0.8490
Epoch 13/100
 - 3s - loss: 0.0651 - accuracy: 0.9773 - val_loss: 0.6221 - val_accuracy: 0.8790
Epoch 14/100
 - 3s - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.7114 - val_accuracy: 0.8797


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:23<02:46, 83.19s/it][A[A2019-09-26 19:29:57,518 - knowledge_transfer - INFO - Observer mnist_21_cl_7_5.npy
I0926 19:29:57.518908 140696480909056 knowledge_transfer.py:94] Observer mnist_21_cl_7_5.npy
2019-09-26 19:29:57,519 - knowledge_transfer - INFO - data already initialised
I0926 19:29:57.519176 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:29:57,553 - knowledge_transfer - INFO - test with geneo init
I0926 19:29:57.553628 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:29:57,604 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:29:57.604528 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:29:57,628 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:29:57.628664 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:30:44,470 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:30:44.470659 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:30:44,471 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:30:44.471262 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00014: early stopping
conv2d_15
True
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_15 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_15 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00012: early stopping
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_16 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_16 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 3.4029 - accuracy: 0.6669 - val_loss: 0.5630 - val_accuracy: 0.7143
Epoch 2/100
 - 4s - loss: 0.4645 - accuracy: 0.7826 - val_loss: 0.5727 - val_accuracy: 0.7613
Epoch 3/100
 - 4s - loss: 0.4197 - accuracy: 0.8099 - val_loss: 0.4684 - val_accuracy: 0.7977
Epoch 4/100
 - 4s - loss: 0.3420 - accuracy: 0.8563 - val_loss: 0.5088 - val_accuracy: 0.7663
Epoch 5/100
 - 4s - loss: 0.3012 - accuracy: 0.8761 - val_loss: 0.4138 - val_accuracy: 0.8497
Epoch 6/100
 - 4s - loss: 0.2597 - accuracy: 0.8954 - val_loss: 0.5196 - val_accuracy: 0.8250
Epoch 7/100
 - 4s - loss: 0.2401 - accuracy: 0.9041 - val_loss: 0.5484 - val_accuracy: 0.7747
Epoch 8/100
 - 4s - loss: 0.2210 - accuracy: 0.9136 - val_loss: 0.5176 - val_accuracy: 0.8287
Epoch 9/100
 - 4s - loss: 0.1751 - accuracy: 0.9319 - val_loss: 0.5544 - val_accuracy: 0.8293
Epoch 10/100
 - 4s - loss: 0.1532 - accuracy: 0.9406 - val_loss: 0.5205 - val_accuracy: 0.8403


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [02:49<01:24, 84.17s/it][A[A2019-09-26 19:31:23,971 - knowledge_transfer - INFO - Observer mnist_11_cl_7_5.npy
I0926 19:31:23.971360 140696480909056 knowledge_transfer.py:94] Observer mnist_11_cl_7_5.npy
2019-09-26 19:31:23,971 - knowledge_transfer - INFO - data already initialised
I0926 19:31:23.971715 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:31:23,989 - knowledge_transfer - INFO - test with geneo init
I0926 19:31:23.989372 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:31:24,035 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:31:24.035129 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:31:24,057 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:31:24.057051 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:31:45,489 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:31:45.489888 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:31:45,490 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:31:45.490226 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00010: early stopping
conv2d_17
True
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_17 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_17 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_17 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_18 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_18 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_18 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 6.6216 - accuracy: 0.7589 - val_loss: 0.4066 - val_accuracy: 0.8357
Epoch 2/100
 - 3s - loss: 0.2696 - accuracy: 0.8929 - val_loss: 0.3286 - val_accuracy: 0.8783
Epoch 3/100
 - 3s - loss: 0.1603 - accuracy: 0.9410 - val_loss: 0.3132 - val_accuracy: 0.8870
Epoch 4/100
 - 3s - loss: 0.1063 - accuracy: 0.9603 - val_loss: 0.2913 - val_accuracy: 0.8963
Epoch 5/100
 - 3s - loss: 0.0721 - accuracy: 0.9746 - val_loss: 0.5692 - val_accuracy: 0.8377
Epoch 6/100
 - 3s - loss: 0.0585 - accuracy: 0.9803 - val_loss: 0.3318 - val_accuracy: 0.9007
Epoch 7/100
 - 3s - loss: 0.0602 - accuracy: 0.9776 - val_loss: 0.5061 - val_accuracy: 0.8723
Epoch 8/100
 - 3s - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.5417 - val_accuracy: 0.8620
Epoch 9/100
 - 3s - loss: 0.0691 - accuracy: 0.9734 - val_loss: 0.3937 - val_accuracy: 0.8960
Epoch 10/100
 - 3s - loss: 0.0410 - accuracy: 0.9851 - val_loss: 0.4177 - val_accuracy: 0.8990
Epoch 11/100
 - 3s - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.4352 - val_accuracy: 0.9010
Epoch 12/100
 - 3s - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.4208 - val_accuracy: 0.8983
Epoch 13/100
 - 3s - loss: 0.0413 - accuracy: 0.9876 - val_loss: 0.4693 - val_accuracy: 0.8907
Epoch 14/100
 - 3s - loss: 0.0539 - accuracy: 0.9803 - val_loss: 0.5605 - val_accuracy: 0.8733
Epoch 15/100
 - 3s - loss: 0.0615 - accuracy: 0.9777 - val_loss: 0.5588 - val_accuracy: 0.8930
Epoch 16/100
 - 3s - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.5872 - val_accuracy: 0.8890


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:06<00:00, 81.86s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:06<00:00, 82.04s/it]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [14:18<00:00, 293.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [14:18<00:00, 286.18s/it]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [14:18<28:37, 858.53s/it]
  0%|          | 0/3 [00:00<?, ?it/s][A2019-09-26 19:32:40,448 - knowledge_transfer - INFO - Working on dataset ./train_all_data/500_ops_40exs cifar10
I0926 19:32:40.448136 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/500_ops_40exs cifar10


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:32:40,448 - knowledge_transfer - INFO - Observer cifar10_7_cl_4_0.npy
I0926 19:32:40.448536 140696480909056 knowledge_transfer.py:94] Observer cifar10_7_cl_4_0.npy
2019-09-26 19:32:40,448 - knowledge_transfer - INFO - initialize data
I0926 19:32:40.448668 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   0%|          | 44/10000 [00:00<00:22, 437.51it/s][A[A[A


preprocessing train:   2%|â–         | 152/10000 [00:00<00:18, 532.34it/s][A[A[A


preprocessing train:   3%|â–Ž         | 296/10000 [00:00<00:14, 656.16it/s][A[A[A


preprocessing train:   5%|â–         | 459/10000 [00:00<00:11, 798.76it/s][A[A[A


preprocessing train:   6%|â–Œ         | 620/10000 [00:00<00:09, 940.63it/s][A[A[A


preprocessing train:   8%|â–Š         | 784/10000 [00:00<00:08, 1078.09it/s][A[A[A


preprocessing train:   9%|â–‰         | 946/10000 [00:00<00:07, 1197.77it/s][A[A[A


preprocessing train:  11%|â–ˆ         | 1109/10000 [00:00<00:06, 1299.87it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1272/10000 [00:00<00:06, 1383.30it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1436/10000 [00:01<00:05, 1450.39it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1599/10000 [00:01<00:05, 1498.72it/s][A[A[A


preprocessing train:  18%|â–ˆâ–Š        | 1762/10000 [00:01<00:05, 1534.54it/s][A[A[A


preprocessing train:  19%|â–ˆâ–‰        | 1921/10000 [00:01<00:05, 1468.43it/s][A[A[A


preprocessing train:  21%|â–ˆâ–ˆ        | 2078/10000 [00:01<00:05, 1495.20it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–Ž       | 2250/10000 [00:01<00:04, 1556.08it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–       | 2432/10000 [00:01<00:04, 1626.52it/s][A[A[A


preprocessing train:  26%|â–ˆâ–ˆâ–Œ       | 2601/10000 [00:01<00:04, 1642.94it/s][A[A[A


preprocessing train:  28%|â–ˆâ–ˆâ–Š       | 2775/10000 [00:01<00:04, 1670.26it/s][A[A[A


preprocessing train:  29%|â–ˆâ–ˆâ–‰       | 2944/10000 [00:01<00:04, 1633.02it/s][A[A[A


preprocessing train:  31%|â–ˆâ–ˆâ–ˆ       | 3109/10000 [00:02<00:04, 1620.14it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3272/10000 [00:02<00:04, 1614.74it/s][A[A[A


preprocessing train:  34%|â–ˆâ–ˆâ–ˆâ–      | 3435/10000 [00:02<00:04, 1611.08it/s][A[A[A


preprocessing train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3597/10000 [00:02<00:03, 1607.19it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3759/10000 [00:02<00:03, 1601.25it/s][A[A[A


preprocessing train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3920/10000 [00:02<00:03, 1597.77it/s][A[A[A


preprocessing train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4085/10000 [00:02<00:03, 1612.13it/s][A[A[A


preprocessing train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4258/10000 [00:02<00:03, 1645.24it/s][A[A[A


preprocessing train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4423/10000 [00:02<00:03, 1625.71it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4586/10000 [00:02<00:03, 1614.42it/s][A[A[A


preprocessing train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4748/10000 [00:03<00:03, 1605.83it/s][A[A[A


preprocessing train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4909/10000 [00:03<00:03, 1598.61it/s][A[A[A


preprocessing train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5069/10000 [00:03<00:03, 1593.97it/s][A[A[A


preprocessing train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5229/10000 [00:03<00:02, 1590.42it/s][A[A[A


preprocessing train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5389/10000 [00:03<00:02, 1589.21it/s][A[A[A


preprocessing train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5548/10000 [00:03<00:02, 1588.12it/s][A[A[A


preprocessing train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5707/10000 [00:03<00:02, 1588.46it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5866/10000 [00:03<00:02, 1587.41it/s][A[A[A


preprocessing train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6025/10000 [00:03<00:02, 1587.65it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6186/10000 [00:03<00:02, 1592.61it/s][A[A[A


preprocessing train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6347/10000 [00:04<00:02, 1596.14it/s][A[A[A


preprocessing train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6508/10000 [00:04<00:02, 1599.75it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6670/10000 [00:04<00:02, 1603.81it/s][A[A[A


preprocessing train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6832/10000 [00:04<00:01, 1606.56it/s][A[A[A


preprocessing train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6994/10000 [00:04<00:01, 1609.25it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7156/10000 [00:04<00:01, 1610.90it/s][A[A[A


preprocessing train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7318/10000 [00:04<00:01, 1610.62it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7481/10000 [00:04<00:01, 1613.48it/s][A[A[A


preprocessing train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7643/10000 [00:04<00:01, 1613.68it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7805/10000 [00:04<00:01, 1612.22it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7967/10000 [00:05<00:01, 1590.75it/s][A[A[A


preprocessing train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8127/10000 [00:05<00:01, 1582.45it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8286/10000 [00:05<00:01, 1578.57it/s][A[A[A


preprocessing train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8444/10000 [00:05<00:00, 1576.15it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8602/10000 [00:05<00:00, 1570.81it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8760/10000 [00:05<00:00, 1568.63it/s][A[A[A


preprocessing train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8917/10000 [00:05<00:00, 1568.43it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9075/10000 [00:05<00:00, 1570.90it/s][A[A[A


preprocessing train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9234/10000 [00:05<00:00, 1574.29it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9393/10000 [00:05<00:00, 1576.72it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9552/10000 [00:06<00:00, 1578.74it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9711/10000 [00:06<00:00, 1580.26it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9870/10000 [00:06<00:00, 1579.04it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1571.93it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   8%|â–Š         | 155/2000 [00:00<00:01, 1541.66it/s][A[A[A


preprocessing test:  15%|â–ˆâ–        | 295/2000 [00:00<00:01, 1493.97it/s][A[A[A


preprocessing test:  22%|â–ˆâ–ˆâ–       | 434/2000 [00:00<00:01, 1459.92it/s][A[A[A


preprocessing test:  29%|â–ˆâ–ˆâ–‰       | 582/2000 [00:00<00:00, 1463.68it/s][A[A[A


preprocessing test:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 738/2000 [00:00<00:00, 1490.91it/s][A[A[A


preprocessing test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 895/2000 [00:00<00:00, 1512.71it/s][A[A[A


preprocessing test:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1053/2000 [00:00<00:00, 1530.10it/s][A[A[A


preprocessing test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1209/2000 [00:00<00:00, 1538.83it/s][A[A[A


preprocessing test:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1357/2000 [00:00<00:00, 1520.00it/s][A[A[A


preprocessing test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1503/2000 [00:01<00:00, 1479.77it/s][A[A[A


preprocessing test:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1649/2000 [00:01<00:00, 1472.54it/s][A[A[A


preprocessing test:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1800/2000 [00:01<00:00, 1483.12it/s][A[A[A


preprocessing test:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1952/2000 [00:01<00:00, 1491.86it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1492.07it/s]
2019-09-26 19:32:48,419 - knowledge_transfer - INFO - test with geneo init
I0926 19:32:48.419211 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:32:48,466 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:32:48.466220 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:32:48,488 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:32:48.488203 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:33:09,804 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:33:09.804937 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:33:09,805 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:33:09.805408 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00016: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [4, 0] 
conv2d_19
True
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_19 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_19 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_19 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_20 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_20 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.1055 - accuracy: 0.9959 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:51<01:43, 51.58s/it][A[A2019-09-26 19:33:32,028 - knowledge_transfer - INFO - Observer cifar10_11_cl_4_0.npy
I0926 19:33:32.028173 140696480909056 knowledge_transfer.py:94] Observer cifar10_11_cl_4_0.npy
2019-09-26 19:33:32,028 - knowledge_transfer - INFO - initialize data
I0926 19:33:32.028439 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 85/10000 [00:00<00:11, 843.46it/s][A[A[A


preprocessing train:   2%|â–         | 190/10000 [00:00<00:10, 895.63it/s][A[A[A


preprocessing train:   3%|â–Ž         | 337/10000 [00:00<00:09, 1014.08it/s][A[A[A


preprocessing train:   5%|â–         | 493/10000 [00:00<00:08, 1131.95it/s][A[A[A


preprocessing train:   6%|â–‹         | 649/10000 [00:00<00:07, 1231.97it/s][A[A[A


preprocessing train:   8%|â–Š         | 804/10000 [00:00<00:07, 1312.20it/s][A[A[A


preprocessing train:  10%|â–‰         | 960/10000 [00:00<00:06, 1376.53it/s][A[A[A


preprocessing train:  11%|â–ˆ         | 1115/10000 [00:00<00:06, 1424.23it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1270/10000 [00:00<00:05, 1459.45it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1428/10000 [00:01<00:05, 1491.93it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1587/10000 [00:01<00:05, 1518.29it/s][A[A[A


preprocessing train:  17%|â–ˆâ–‹        | 1746/10000 [00:01<00:05, 1537.72it/s][A[A[A


preprocessing train:  19%|â–ˆâ–‰        | 1905/10000 [00:01<00:05, 1552.80it/s][A[A[A


preprocessing train:  21%|â–ˆâ–ˆ        | 2066/10000 [00:01<00:05, 1567.02it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–       | 2225/10000 [00:01<00:04, 1572.26it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–       | 2384/10000 [00:01<00:04, 1575.99it/s][A[A[A


preprocessing train:  25%|â–ˆâ–ˆâ–Œ       | 2543/10000 [00:01<00:04, 1579.51it/s][A[A[A


preprocessing train:  27%|â–ˆâ–ˆâ–‹       | 2703/10000 [00:01<00:04, 1584.10it/s][A[A[A


preprocessing train:  29%|â–ˆâ–ˆâ–Š       | 2862/10000 [00:01<00:04, 1583.70it/s][A[A[A


preprocessing train:  30%|â–ˆâ–ˆâ–ˆ       | 3022/10000 [00:02<00:04, 1585.75it/s][A[A[A


preprocessing train:  32%|â–ˆâ–ˆâ–ˆâ–      | 3183/10000 [00:02<00:04, 1592.02it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3343/10000 [00:02<00:04, 1593.03it/s][A[A[A


preprocessing train:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 3503/10000 [00:02<00:04, 1563.13it/s][A[A[A


preprocessing train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3660/10000 [00:02<00:04, 1548.61it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3817/10000 [00:02<00:03, 1553.72it/s][A[A[A


preprocessing train:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3974/10000 [00:02<00:03, 1557.80it/s][A[A[A


preprocessing train:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4132/10000 [00:02<00:03, 1564.25it/s][A[A[A


preprocessing train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4294/10000 [00:02<00:03, 1579.73it/s][A[A[A


preprocessing train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4457/10000 [00:02<00:03, 1592.96it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4617/10000 [00:03<00:03, 1588.35it/s][A[A[A


preprocessing train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4776/10000 [00:03<00:03, 1513.21it/s][A[A[A


preprocessing train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4929/10000 [00:03<00:03, 1480.74it/s][A[A[A


preprocessing train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5084/10000 [00:03<00:03, 1500.16it/s][A[A[A


preprocessing train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5240/10000 [00:03<00:03, 1515.51it/s][A[A[A


preprocessing train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5397/10000 [00:03<00:03, 1529.07it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5551/10000 [00:03<00:02, 1531.53it/s][A[A[A


preprocessing train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5705/10000 [00:03<00:02, 1532.87it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5860/10000 [00:03<00:02, 1537.30it/s][A[A[A


preprocessing train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6015/10000 [00:03<00:02, 1539.17it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6169/10000 [00:04<00:02, 1536.58it/s][A[A[A


preprocessing train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6323/10000 [00:04<00:02, 1535.15it/s][A[A[A


preprocessing train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6477/10000 [00:04<00:02, 1532.04it/s][A[A[A


preprocessing train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6631/10000 [00:04<00:02, 1497.34it/s][A[A[A


preprocessing train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6783/10000 [00:04<00:02, 1501.88it/s][A[A[A


preprocessing train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6938/10000 [00:04<00:02, 1514.73it/s][A[A[A


preprocessing train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7090/10000 [00:04<00:01, 1501.43it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7241/10000 [00:04<00:01, 1469.21it/s][A[A[A


preprocessing train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7389/10000 [00:04<00:01, 1443.61it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7534/10000 [00:04<00:01, 1426.39it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7677/10000 [00:05<00:01, 1423.66it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7823/10000 [00:05<00:01, 1432.27it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7969/10000 [00:05<00:01, 1438.08it/s][A[A[A


preprocessing train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8115/10000 [00:05<00:01, 1442.53it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8261/10000 [00:05<00:01, 1445.94it/s][A[A[A


preprocessing train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8406/10000 [00:05<00:01, 1446.77it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8552/10000 [00:05<00:01, 1447.97it/s][A[A[A


preprocessing train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8698/10000 [00:05<00:00, 1448.96it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8844/10000 [00:05<00:00, 1449.77it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8990/10000 [00:05<00:00, 1450.30it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9136/10000 [00:06<00:00, 1450.19it/s][A[A[A


preprocessing train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9282/10000 [00:06<00:00, 1451.75it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9429/10000 [00:06<00:00, 1454.48it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9576/10000 [00:06<00:00, 1457.63it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9723/10000 [00:06<00:00, 1460.71it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9870/10000 [00:06<00:00, 1424.73it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1497.87it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   8%|â–Š         | 165/2000 [00:00<00:01, 1641.71it/s][A[A[A


preprocessing test:  17%|â–ˆâ–‹        | 332/2000 [00:00<00:01, 1649.72it/s][A[A[A


preprocessing test:  25%|â–ˆâ–ˆâ–Œ       | 502/2000 [00:00<00:00, 1664.14it/s][A[A[A


preprocessing test:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 670/2000 [00:00<00:00, 1666.85it/s][A[A[A


preprocessing test:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 838/2000 [00:00<00:00, 1670.26it/s][A[A[A


preprocessing test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1004/2000 [00:00<00:00, 1664.88it/s][A[A[A


preprocessing test:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1169/2000 [00:00<00:00, 1660.30it/s][A[A[A


preprocessing test:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1335/2000 [00:00<00:00, 1658.54it/s][A[A[A


preprocessing test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1501/2000 [00:00<00:00, 1658.70it/s][A[A[A


preprocessing test:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1666/2000 [00:01<00:00, 1654.34it/s][A[A[A


preprocessing test:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1833/2000 [00:01<00:00, 1657.27it/s][A[A[A


preprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1996/2000 [00:01<00:00, 1635.18it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1655.02it/s]
2019-09-26 19:33:40,195 - knowledge_transfer - INFO - test with geneo init
I0926 19:33:40.195652 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:33:40,243 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:33:40.243323 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:33:40,266 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:33:40.266937 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:34:01,804 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:34:01.804218 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:34:01,804 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:34:01.804697 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [4, 0] 
conv2d_21
True
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_21 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_21 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_22 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_22 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_22 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.1626 - accuracy: 0.9954 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [01:43<00:51, 51.63s/it][A[A2019-09-26 19:34:23,771 - knowledge_transfer - INFO - Observer cifar10_21_cl_4_0.npy
I0926 19:34:23.771841 140696480909056 knowledge_transfer.py:94] Observer cifar10_21_cl_4_0.npy
2019-09-26 19:34:23,772 - knowledge_transfer - INFO - initialize data
I0926 19:34:23.772106 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   0%|          | 39/10000 [00:00<00:25, 384.50it/s][A[A[A


preprocessing train:   1%|â–         | 138/10000 [00:00<00:20, 470.72it/s][A[A[A


preprocessing train:   3%|â–Ž         | 298/10000 [00:00<00:16, 596.89it/s][A[A[A


preprocessing train:   5%|â–         | 457/10000 [00:00<00:12, 734.32it/s][A[A[A


preprocessing train:   6%|â–Œ         | 617/10000 [00:00<00:10, 875.87it/s][A[A[A


preprocessing train:   8%|â–Š         | 776/10000 [00:00<00:09, 1011.86it/s][A[A[A


preprocessing train:   9%|â–‰         | 937/10000 [00:00<00:07, 1138.18it/s][A[A[A


preprocessing train:  11%|â–ˆ         | 1101/10000 [00:00<00:07, 1252.74it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1268/10000 [00:00<00:06, 1353.38it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1436/10000 [00:01<00:05, 1436.33it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1602/10000 [00:01<00:05, 1495.03it/s][A[A[A


preprocessing train:  18%|â–ˆâ–Š        | 1764/10000 [00:01<00:05, 1528.33it/s][A[A[A


preprocessing train:  19%|â–ˆâ–‰        | 1925/10000 [00:01<00:05, 1550.69it/s][A[A[A


preprocessing train:  21%|â–ˆâ–ˆ        | 2088/10000 [00:01<00:05, 1571.78it/s][A[A[A


preprocessing train:  23%|â–ˆâ–ˆâ–Ž       | 2252/10000 [00:01<00:04, 1591.05it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–       | 2416/10000 [00:01<00:04, 1604.47it/s][A[A[A


preprocessing train:  26%|â–ˆâ–ˆâ–Œ       | 2580/10000 [00:01<00:04, 1612.36it/s][A[A[A


preprocessing train:  28%|â–ˆâ–ˆâ–Š       | 2756/10000 [00:01<00:04, 1652.95it/s][A[A[A


preprocessing train:  29%|â–ˆâ–ˆâ–‰       | 2923/10000 [00:01<00:04, 1633.65it/s][A[A[A


preprocessing train:  31%|â–ˆâ–ˆâ–ˆ       | 3088/10000 [00:02<00:04, 1618.66it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3251/10000 [00:02<00:04, 1619.02it/s][A[A[A


preprocessing train:  34%|â–ˆâ–ˆâ–ˆâ–      | 3414/10000 [00:02<00:04, 1606.62it/s][A[A[A


preprocessing train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3575/10000 [00:02<00:04, 1598.01it/s][A[A[A


preprocessing train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3736/10000 [00:02<00:03, 1592.63it/s][A[A[A


preprocessing train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3896/10000 [00:02<00:03, 1590.98it/s][A[A[A


preprocessing train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4056/10000 [00:02<00:03, 1587.93it/s][A[A[A


preprocessing train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4215/10000 [00:02<00:03, 1586.87it/s][A[A[A


preprocessing train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4374/10000 [00:02<00:03, 1581.81it/s][A[A[A


preprocessing train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4533/10000 [00:02<00:03, 1576.32it/s][A[A[A


preprocessing train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4691/10000 [00:03<00:03, 1570.40it/s][A[A[A


preprocessing train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4849/10000 [00:03<00:03, 1570.39it/s][A[A[A


preprocessing train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5007/10000 [00:03<00:03, 1572.26it/s][A[A[A


preprocessing train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5165/10000 [00:03<00:03, 1568.18it/s][A[A[A


preprocessing train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5322/10000 [00:03<00:03, 1522.35it/s][A[A[A


preprocessing train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5475/10000 [00:03<00:03, 1491.24it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5625/10000 [00:03<00:02, 1469.33it/s][A[A[A


preprocessing train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5773/10000 [00:03<00:02, 1453.46it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5920/10000 [00:03<00:02, 1456.24it/s][A[A[A


preprocessing train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6084/10000 [00:03<00:02, 1504.15it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6235/10000 [00:04<00:02, 1504.82it/s][A[A[A


preprocessing train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6386/10000 [00:04<00:02, 1505.82it/s][A[A[A


preprocessing train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6537/10000 [00:04<00:02, 1490.04it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6688/10000 [00:04<00:02, 1494.00it/s][A[A[A


preprocessing train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6839/10000 [00:04<00:02, 1497.63it/s][A[A[A


preprocessing train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6997/10000 [00:04<00:01, 1521.04it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7156/10000 [00:04<00:01, 1538.41it/s][A[A[A


preprocessing train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7315/10000 [00:04<00:01, 1550.79it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7474/10000 [00:04<00:01, 1561.14it/s][A[A[A


preprocessing train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7633/10000 [00:04<00:01, 1568.99it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7791/10000 [00:05<00:01, 1572.23it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7950/10000 [00:05<00:01, 1575.91it/s][A[A[A


preprocessing train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8109/10000 [00:05<00:01, 1578.52it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8267/10000 [00:05<00:01, 1563.58it/s][A[A[A


preprocessing train:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8426/10000 [00:05<00:01, 1569.63it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8584/10000 [00:05<00:00, 1560.69it/s][A[A[A


preprocessing train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8741/10000 [00:05<00:00, 1499.81it/s][A[A[A


preprocessing train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8892/10000 [00:05<00:00, 1500.95it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9049/10000 [00:05<00:00, 1518.81it/s][A[A[A


preprocessing train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9208/10000 [00:05<00:00, 1539.14it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9365/10000 [00:06<00:00, 1547.02it/s][A[A[A


preprocessing train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9524/10000 [00:06<00:00, 1559.51it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9685/10000 [00:06<00:00, 1572.28it/s][A[A[A


preprocessing train:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9845/10000 [00:06<00:00, 1578.90it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1541.17it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   8%|â–Š         | 160/2000 [00:00<00:01, 1590.48it/s][A[A[A


preprocessing test:  16%|â–ˆâ–Œ        | 322/2000 [00:00<00:01, 1596.47it/s][A[A[A


preprocessing test:  24%|â–ˆâ–ˆâ–       | 483/2000 [00:00<00:00, 1600.44it/s][A[A[A


preprocessing test:  32%|â–ˆâ–ˆâ–ˆâ–      | 645/2000 [00:00<00:00, 1605.59it/s][A[A[A


preprocessing test:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 805/2000 [00:00<00:00, 1603.86it/s][A[A[A


preprocessing test:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 965/2000 [00:00<00:00, 1601.48it/s][A[A[A


preprocessing test:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1133/2000 [00:00<00:00, 1622.99it/s][A[A[A


preprocessing test:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1311/2000 [00:00<00:00, 1665.31it/s][A[A[A


preprocessing test:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1469/2000 [00:00<00:00, 1631.24it/s][A[A[A


preprocessing test:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1629/2000 [00:01<00:00, 1620.30it/s][A[A[A


preprocessing test:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1789/2000 [00:01<00:00, 1612.61it/s][A[A[A


preprocessing test:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1949/2000 [00:01<00:00, 1607.11it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1616.83it/s]
2019-09-26 19:34:31,836 - knowledge_transfer - INFO - test with geneo init
I0926 19:34:31.836872 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:34:31,883 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:34:31.883299 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:34:31,907 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:34:31.907282 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:35:11,451 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:35:11.451475 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:35:11,451 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:35:11.451838 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [4, 0] 
conv2d_23
True
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_23 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_23 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_23 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00010: early stopping
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_24 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_24 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_24 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.0101 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:56<00:00, 58.06s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:56<00:00, 58.79s/it]

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [02:56<05:52, 176.37s/it][A2019-09-26 19:35:36,822 - knowledge_transfer - INFO - Working on dataset ./train_all_data/500_ops_40exs fashion_mnist
I0926 19:35:36.822062 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/500_ops_40exs fashion_mnist


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:35:36,822 - knowledge_transfer - INFO - Observer fashion_mnist_7_cl_6_2.npy
I0926 19:35:36.822510 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_7_cl_6_2.npy
2019-09-26 19:35:36,822 - knowledge_transfer - INFO - data already initialised
I0926 19:35:36.822645 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:35:36,837 - knowledge_transfer - INFO - test with geneo init
I0926 19:35:36.837287 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:35:36,888 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:35:36.888171 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:35:36,911 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:35:36.911438 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:35:59,208 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:35:59.208397 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:35:59,208 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:35:59.208787 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
conv2d_25
True
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_25 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_25 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_25 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_26 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_26 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:45<01:30, 45.40s/it][A[A2019-09-26 19:36:22,222 - knowledge_transfer - INFO - Observer fashion_mnist_11_cl_6_2.npy
I0926 19:36:22.222917 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_11_cl_6_2.npy
2019-09-26 19:36:22,223 - knowledge_transfer - INFO - data already initialised
I0926 19:36:22.223295 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:36:22,241 - knowledge_transfer - INFO - test with geneo init
I0926 19:36:22.241573 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:36:22,292 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:36:22.292014 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:36:22,317 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:36:22.317049 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:36:44,931 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:36:44.931461 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:36:44,931 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:36:44.931901 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
conv2d_27
True
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_27 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_27 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_27 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_28 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_28 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_28 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.0082 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [01:31<00:45, 45.55s/it][A[A2019-09-26 19:37:08,110 - knowledge_transfer - INFO - Observer fashion_mnist_21_cl_6_2.npy
I0926 19:37:08.110405 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_21_cl_6_2.npy
2019-09-26 19:37:08,110 - knowledge_transfer - INFO - data already initialised
I0926 19:37:08.110628 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:37:08,144 - knowledge_transfer - INFO - test with geneo init
I0926 19:37:08.144609 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:37:08,196 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:37:08.196725 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:37:08,221 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:37:08.221196 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:37:33,378 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:37:33.378388 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:37:33,378 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:37:33.378682 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
conv2d_29
True
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_29 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_29 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_29 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_30 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_30 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_30 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.1241 - accuracy: 0.9956 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:22<00:00, 47.17s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:22<00:00, 47.41s/it]

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [05:18<02:46, 166.13s/it][A2019-09-26 19:37:59,060 - knowledge_transfer - INFO - Working on dataset ./train_all_data/500_ops_40exs mnist
I0926 19:37:59.060350 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/500_ops_40exs mnist


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:37:59,061 - knowledge_transfer - INFO - Observer mnist_7_cl_3_8.npy
I0926 19:37:59.061050 140696480909056 knowledge_transfer.py:94] Observer mnist_7_cl_3_8.npy
2019-09-26 19:37:59,061 - knowledge_transfer - INFO - data already initialised
I0926 19:37:59.061190 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:37:59,075 - knowledge_transfer - INFO - test with geneo init
I0926 19:37:59.075380 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:37:59,126 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:37:59.126200 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:37:59,150 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:37:59.150647 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:38:21,889 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:38:21.889339 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:38:21,889 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:38:21.889692 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
conv2d_31
True
Model: "sequential_31"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_31 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_31 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_32"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_32 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_32 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_32 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.1616 - accuracy: 0.9954 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:46<01:33, 46.61s/it][A[A2019-09-26 19:38:45,669 - knowledge_transfer - INFO - Observer mnist_11_cl_3_8.npy
I0926 19:38:45.669099 140696480909056 knowledge_transfer.py:94] Observer mnist_11_cl_3_8.npy
2019-09-26 19:38:45,669 - knowledge_transfer - INFO - data already initialised
I0926 19:38:45.669319 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:38:45,687 - knowledge_transfer - INFO - test with geneo init
I0926 19:38:45.687881 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:38:45,738 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:38:45.738053 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:38:45,767 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:38:45.767274 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:39:08,997 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:39:08.997002 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:39:08,997 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:39:08.997551 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
conv2d_33
True
Model: "sequential_33"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_33 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_33 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_33 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_34"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_34 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_34 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_34 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_34 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 3.8036e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 3s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [01:33<00:46, 46.67s/it][A[A2019-09-26 19:39:32,476 - knowledge_transfer - INFO - Observer mnist_21_cl_3_8.npy
I0926 19:39:32.476375 140696480909056 knowledge_transfer.py:94] Observer mnist_21_cl_3_8.npy
2019-09-26 19:39:32,476 - knowledge_transfer - INFO - data already initialised
I0926 19:39:32.476635 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:39:32,513 - knowledge_transfer - INFO - test with geneo init
I0926 19:39:32.513057 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:39:32,564 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:39:32.564343 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:39:32,588 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:39:32.588546 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:39:58,079 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:39:58.079196 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:39:58,079 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:39:58.079741 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
conv2d_35
True
Model: "sequential_35"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_35 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_35 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_35 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_35 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00006: early stopping
Model: "sequential_36"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_36 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_36 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_36 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 0.1587 - accuracy: 0.9954 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 2/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 3/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 4/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 5/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000
Epoch 6/100
 - 4s - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:25<00:00, 48.17s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:25<00:00, 48.36s/it]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [07:43<00:00, 159.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [07:43<00:00, 154.57s/it]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [22:02<12:20, 740.08s/it]
  0%|          | 0/3 [00:00<?, ?it/s][A2019-09-26 19:40:24,148 - knowledge_transfer - INFO - Working on dataset ./train_all_data/750_ops_20exs cifar10
I0926 19:40:24.148169 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/750_ops_20exs cifar10


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:40:24,148 - knowledge_transfer - INFO - Observer cifar10_21_cl_1_7.npy
I0926 19:40:24.148599 140696480909056 knowledge_transfer.py:94] Observer cifar10_21_cl_1_7.npy
2019-09-26 19:40:24,148 - knowledge_transfer - INFO - initialize data
I0926 19:40:24.148730 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 94/10000 [00:00<00:10, 935.39it/s][A[A[A


preprocessing train:   2%|â–         | 200/10000 [00:00<00:10, 968.10it/s][A[A[A


preprocessing train:   4%|â–Ž         | 351/10000 [00:00<00:08, 1084.72it/s][A[A[A


preprocessing train:   5%|â–Œ         | 507/10000 [00:00<00:07, 1192.68it/s][A[A[A


preprocessing train:   7%|â–‹         | 672/10000 [00:00<00:07, 1300.07it/s][A[A[A


preprocessing train:   8%|â–Š         | 834/10000 [00:00<00:06, 1381.83it/s][A[A[A


preprocessing train:  10%|â–‰         | 983/10000 [00:00<00:06, 1410.76it/s][A[A[A


preprocessing train:  11%|â–ˆâ–        | 1129/10000 [00:00<00:06, 1425.11it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1274/10000 [00:00<00:06, 1431.81it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1419/10000 [00:01<00:05, 1435.73it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1588/10000 [00:01<00:05, 1501.82it/s][A[A[A


preprocessing train:  18%|â–ˆâ–Š        | 1762/10000 [00:01<00:05, 1563.75it/s][A[A[A


preprocessing train:  19%|â–ˆâ–‰        | 1938/10000 [00:01<00:04, 1616.34it/s][A[A[A


preprocessing train:  21%|â–ˆâ–ˆ        | 2118/10000 [00:01<00:04, 1667.16it/s][A[A[A


preprocessing train:  23%|â–ˆâ–ˆâ–Ž       | 2296/10000 [00:01<00:04, 1696.26it/s][A[A[A


preprocessing train:  25%|â–ˆâ–ˆâ–       | 2467/10000 [00:01<00:04, 1625.04it/s][A[A[A


preprocessing train:  26%|â–ˆâ–ˆâ–‹       | 2631/10000 [00:01<00:04, 1565.92it/s][A[A[A


preprocessing train:  28%|â–ˆâ–ˆâ–Š       | 2789/10000 [00:01<00:04, 1563.65it/s][A[A[A


preprocessing train:  30%|â–ˆâ–ˆâ–‰       | 2962/10000 [00:01<00:04, 1608.82it/s][A[A[A


preprocessing train:  31%|â–ˆâ–ˆâ–ˆâ–      | 3139/10000 [00:02<00:04, 1652.60it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3317/10000 [00:02<00:03, 1686.32it/s][A[A[A


preprocessing train:  35%|â–ˆâ–ˆâ–ˆâ–      | 3490/10000 [00:02<00:03, 1698.73it/s][A[A[A


preprocessing train:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3666/10000 [00:02<00:03, 1714.94it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3838/10000 [00:02<00:03, 1700.80it/s][A[A[A


preprocessing train:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4009/10000 [00:02<00:03, 1620.06it/s][A[A[A


preprocessing train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4173/10000 [00:02<00:03, 1558.82it/s][A[A[A


preprocessing train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4331/10000 [00:02<00:03, 1527.30it/s][A[A[A


preprocessing train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4485/10000 [00:02<00:03, 1505.79it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4645/10000 [00:02<00:03, 1531.03it/s][A[A[A


preprocessing train:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4806/10000 [00:03<00:03, 1553.06it/s][A[A[A


preprocessing train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4967/10000 [00:03<00:03, 1566.83it/s][A[A[A


preprocessing train:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5125/10000 [00:03<00:03, 1549.69it/s][A[A[A


preprocessing train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5281/10000 [00:03<00:03, 1507.08it/s][A[A[A


preprocessing train:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5433/10000 [00:03<00:03, 1477.57it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5582/10000 [00:03<00:03, 1458.19it/s][A[A[A


preprocessing train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5739/10000 [00:03<00:02, 1487.86it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5902/10000 [00:03<00:02, 1526.53it/s][A[A[A


preprocessing train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6065/10000 [00:03<00:02, 1553.98it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6225/10000 [00:04<00:02, 1565.68it/s][A[A[A


preprocessing train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6382/10000 [00:04<00:02, 1522.02it/s][A[A[A


preprocessing train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6535/10000 [00:04<00:02, 1486.45it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6687/10000 [00:04<00:02, 1494.63it/s][A[A[A


preprocessing train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6837/10000 [00:04<00:02, 1488.42it/s][A[A[A


preprocessing train:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6987/10000 [00:04<00:02, 1481.61it/s][A[A[A


preprocessing train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7136/10000 [00:04<00:01, 1477.43it/s][A[A[A


preprocessing train:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7284/10000 [00:04<00:01, 1474.60it/s][A[A[A


preprocessing train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7435/10000 [00:04<00:01, 1483.67it/s][A[A[A


preprocessing train:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7586/10000 [00:04<00:01, 1491.39it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7737/10000 [00:05<00:01, 1494.37it/s][A[A[A


preprocessing train:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7888/10000 [00:05<00:01, 1496.99it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8039/10000 [00:05<00:01, 1498.86it/s][A[A[A


preprocessing train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8191/10000 [00:05<00:01, 1502.87it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8342/10000 [00:05<00:01, 1502.37it/s][A[A[A


preprocessing train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8493/10000 [00:05<00:01, 1485.64it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8649/10000 [00:05<00:00, 1506.53it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8800/10000 [00:05<00:00, 1498.11it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8950/10000 [00:05<00:00, 1496.84it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9100/10000 [00:05<00:00, 1496.30it/s][A[A[A


preprocessing train:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9250/10000 [00:06<00:00, 1477.36it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9398/10000 [00:06<00:00, 1467.19it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9552/10000 [00:06<00:00, 1486.76it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9718/10000 [00:06<00:00, 1534.54it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9884/10000 [00:06<00:00, 1569.37it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1531.28it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   7%|â–‹         | 148/2000 [00:00<00:01, 1470.50it/s][A[A[A


preprocessing test:  14%|â–ˆâ–        | 290/2000 [00:00<00:01, 1453.88it/s][A[A[A


preprocessing test:  22%|â–ˆâ–ˆâ–       | 435/2000 [00:00<00:01, 1452.37it/s][A[A[A


preprocessing test:  29%|â–ˆâ–ˆâ–‰       | 585/2000 [00:00<00:00, 1465.12it/s][A[A[A


preprocessing test:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 736/2000 [00:00<00:00, 1477.84it/s][A[A[A


preprocessing test:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 886/2000 [00:00<00:00, 1483.28it/s][A[A[A


preprocessing test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1037/2000 [00:00<00:00, 1489.11it/s][A[A[A


preprocessing test:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1188/2000 [00:00<00:00, 1494.77it/s][A[A[A


preprocessing test:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1339/2000 [00:00<00:00, 1496.94it/s][A[A[A


preprocessing test:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1490/2000 [00:01<00:00, 1500.36it/s][A[A[A


preprocessing test:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1640/2000 [00:01<00:00, 1498.08it/s][A[A[A


preprocessing test:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1789/2000 [00:01<00:00, 1495.59it/s][A[A[A


preprocessing test:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1937/2000 [00:01<00:00, 1471.31it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1480.08it/s]
2019-09-26 19:40:32,371 - knowledge_transfer - INFO - test with geneo init
I0926 19:40:32.371050 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:40:32,420 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:40:32.420564 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:40:32,446 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:40:32.446434 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:41:44,905 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:41:44.905896 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:41:44,906 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:41:44.906229 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00006: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [1, 7] 
conv2d_37
True
Model: "sequential_37"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_37 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_37 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_37 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_37 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00018: early stopping
Model: "sequential_38"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_38 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_38 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_38 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_38 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 2.1498 - accuracy: 0.8060 - val_loss: 0.3895 - val_accuracy: 0.8480
Epoch 2/100
 - 4s - loss: 0.2910 - accuracy: 0.8859 - val_loss: 0.3405 - val_accuracy: 0.8560
Epoch 3/100
 - 4s - loss: 0.2579 - accuracy: 0.9010 - val_loss: 0.4554 - val_accuracy: 0.8110
Epoch 4/100
 - 4s - loss: 0.2324 - accuracy: 0.9091 - val_loss: 0.3323 - val_accuracy: 0.8867
Epoch 5/100
 - 4s - loss: 0.1813 - accuracy: 0.9321 - val_loss: 0.3825 - val_accuracy: 0.8730
Epoch 6/100
 - 4s - loss: 0.1429 - accuracy: 0.9453 - val_loss: 0.4451 - val_accuracy: 0.8613
Epoch 7/100
 - 4s - loss: 0.1652 - accuracy: 0.9367 - val_loss: 0.3951 - val_accuracy: 0.8923
Epoch 8/100
 - 4s - loss: 0.1478 - accuracy: 0.9469 - val_loss: 0.4278 - val_accuracy: 0.8907
Epoch 9/100
 - 4s - loss: 0.1481 - accuracy: 0.9437 - val_loss: 0.5847 - val_accuracy: 0.8547
Epoch 10/100
 - 4s - loss: 0.1288 - accuracy: 0.9519 - val_loss: 0.5281 - val_accuracy: 0.8843
Epoch 11/100
 - 4s - loss: 0.1086 - accuracy: 0.9584 - val_loss: 0.5206 - val_accuracy: 0.9017
Epoch 12/100
 - 4s - loss: 0.0826 - accuracy: 0.9741 - val_loss: 0.5349 - val_accuracy: 0.8860
Epoch 13/100
 - 4s - loss: 0.0927 - accuracy: 0.9656 - val_loss: 0.5310 - val_accuracy: 0.9057
Epoch 14/100
 - 4s - loss: 0.1312 - accuracy: 0.9561 - val_loss: 0.5713 - val_accuracy: 0.8950
Epoch 15/100
 - 4s - loss: 0.1031 - accuracy: 0.9663 - val_loss: 0.7538 - val_accuracy: 0.8707
Epoch 16/100
 - 4s - loss: 0.1102 - accuracy: 0.9614 - val_loss: 0.6715 - val_accuracy: 0.8680
Epoch 17/100
 - 4s - loss: 0.0760 - accuracy: 0.9736 - val_loss: 0.7309 - val_accuracy: 0.8767
Epoch 18/100
 - 4s - loss: 0.0626 - accuracy: 0.9800 - val_loss: 0.7662 - val_accuracy: 0.8763


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [02:33<05:06, 153.24s/it][A[A2019-09-26 19:42:57,386 - knowledge_transfer - INFO - Observer cifar10_7_cl_1_7.npy
I0926 19:42:57.386332 140696480909056 knowledge_transfer.py:94] Observer cifar10_7_cl_1_7.npy
2019-09-26 19:42:57,386 - knowledge_transfer - INFO - initialize data
I0926 19:42:57.386774 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 97/10000 [00:00<00:10, 960.56it/s][A[A[A


preprocessing train:   2%|â–         | 193/10000 [00:00<00:10, 958.59it/s][A[A[A


preprocessing train:   3%|â–Ž         | 341/10000 [00:00<00:09, 1070.63it/s][A[A[A


preprocessing train:   5%|â–Œ         | 505/10000 [00:00<00:07, 1193.84it/s][A[A[A


preprocessing train:   7%|â–‹         | 669/10000 [00:00<00:07, 1298.11it/s][A[A[A


preprocessing train:   8%|â–Š         | 831/10000 [00:00<00:06, 1380.12it/s][A[A[A


preprocessing train:  10%|â–‰         | 965/10000 [00:00<00:06, 1363.15it/s][A[A[A


preprocessing train:  11%|â–ˆ         | 1119/10000 [00:00<00:06, 1410.89it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1273/10000 [00:00<00:06, 1446.25it/s][A[A[A


preprocessing train:  14%|â–ˆâ–        | 1428/10000 [00:01<00:05, 1473.57it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1583/10000 [00:01<00:05, 1494.91it/s][A[A[A


preprocessing train:  17%|â–ˆâ–‹        | 1737/10000 [00:01<00:05, 1507.92it/s][A[A[A


preprocessing train:  19%|â–ˆâ–‰        | 1891/10000 [00:01<00:05, 1514.56it/s][A[A[A


preprocessing train:  20%|â–ˆâ–ˆ        | 2045/10000 [00:01<00:05, 1520.48it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–       | 2198/10000 [00:01<00:05, 1522.80it/s][A[A[A


preprocessing train:  24%|â–ˆâ–ˆâ–Ž       | 2352/10000 [00:01<00:05, 1526.73it/s][A[A[A


preprocessing train:  25%|â–ˆâ–ˆâ–Œ       | 2506/10000 [00:01<00:04, 1528.83it/s][A[A[A


preprocessing train:  27%|â–ˆâ–ˆâ–‹       | 2660/10000 [00:01<00:04, 1531.22it/s][A[A[A


preprocessing train:  28%|â–ˆâ–ˆâ–Š       | 2821/10000 [00:01<00:04, 1553.17it/s][A[A[A


preprocessing train:  30%|â–ˆâ–ˆâ–‰       | 2995/10000 [00:02<00:04, 1604.30it/s][A[A[A


preprocessing train:  32%|â–ˆâ–ˆâ–ˆâ–      | 3156/10000 [00:02<00:04, 1602.81it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3317/10000 [00:02<00:04, 1574.89it/s][A[A[A


preprocessing train:  35%|â–ˆâ–ˆâ–ˆâ–      | 3475/10000 [00:02<00:04, 1519.24it/s][A[A[A


preprocessing train:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 3628/10000 [00:02<00:04, 1513.06it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3780/10000 [00:02<00:04, 1513.96it/s][A[A[A


preprocessing train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3933/10000 [00:02<00:03, 1517.98it/s][A[A[A


preprocessing train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4086/10000 [00:02<00:03, 1519.64it/s][A[A[A


preprocessing train:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4239/10000 [00:02<00:03, 1519.68it/s][A[A[A


preprocessing train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4392/10000 [00:02<00:03, 1522.45it/s][A[A[A


preprocessing train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4546/10000 [00:03<00:03, 1526.76it/s][A[A[A


preprocessing train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4700/10000 [00:03<00:03, 1529.37it/s][A[A[A


preprocessing train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4854/10000 [00:03<00:03, 1531.44it/s][A[A[A


preprocessing train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5008/10000 [00:03<00:03, 1533.17it/s][A[A[A


preprocessing train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5162/10000 [00:03<00:03, 1534.82it/s][A[A[A


preprocessing train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5316/10000 [00:03<00:03, 1535.90it/s][A[A[A


preprocessing train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5470/10000 [00:03<00:02, 1535.95it/s][A[A[A


preprocessing train:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5625/10000 [00:03<00:02, 1537.31it/s][A[A[A


preprocessing train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5779/10000 [00:03<00:02, 1537.14it/s][A[A[A


preprocessing train:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5933/10000 [00:03<00:02, 1536.27it/s][A[A[A


preprocessing train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6088/10000 [00:04<00:02, 1537.88it/s][A[A[A


preprocessing train:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6247/10000 [00:04<00:02, 1550.53it/s][A[A[A


preprocessing train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6405/10000 [00:04<00:02, 1557.04it/s][A[A[A


preprocessing train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6561/10000 [00:04<00:02, 1540.17it/s][A[A[A


preprocessing train:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6722/10000 [00:04<00:02, 1558.92it/s][A[A[A


preprocessing train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6900/10000 [00:04<00:01, 1617.97it/s][A[A[A


preprocessing train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7063/10000 [00:04<00:01, 1608.76it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7225/10000 [00:04<00:01, 1592.33it/s][A[A[A


preprocessing train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7385/10000 [00:04<00:01, 1572.66it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7543/10000 [00:04<00:01, 1569.43it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7701/10000 [00:05<00:01, 1570.29it/s][A[A[A


preprocessing train:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7859/10000 [00:05<00:01, 1565.29it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8017/10000 [00:05<00:01, 1569.18it/s][A[A[A


preprocessing train:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8177/10000 [00:05<00:01, 1575.67it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8336/10000 [00:05<00:01, 1579.56it/s][A[A[A


preprocessing train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8495/10000 [00:05<00:00, 1574.73it/s][A[A[A


preprocessing train:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8654/10000 [00:05<00:00, 1578.88it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8818/10000 [00:05<00:00, 1593.13it/s][A[A[A


preprocessing train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8978/10000 [00:05<00:00, 1543.08it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9133/10000 [00:05<00:00, 1502.82it/s][A[A[A


preprocessing train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9284/10000 [00:06<00:00, 1476.77it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9433/10000 [00:06<00:00, 1457.88it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9580/10000 [00:06<00:00, 1447.11it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9732/10000 [00:06<00:00, 1465.74it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9879/10000 [00:06<00:00, 1446.66it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1519.84it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   7%|â–‹         | 149/2000 [00:00<00:01, 1487.35it/s][A[A[A


preprocessing test:  15%|â–ˆâ–        | 299/2000 [00:00<00:01, 1489.84it/s][A[A[A


preprocessing test:  22%|â–ˆâ–ˆâ–Ž       | 450/2000 [00:00<00:01, 1495.31it/s][A[A[A


preprocessing test:  30%|â–ˆâ–ˆâ–ˆ       | 600/2000 [00:00<00:00, 1495.11it/s][A[A[A


preprocessing test:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 750/2000 [00:00<00:00, 1495.67it/s][A[A[A


preprocessing test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 899/2000 [00:00<00:00, 1492.53it/s][A[A[A


preprocessing test:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1045/2000 [00:00<00:00, 1479.47it/s][A[A[A


preprocessing test:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1188/2000 [00:00<00:00, 1463.31it/s][A[A[A


preprocessing test:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1332/2000 [00:00<00:00, 1454.93it/s][A[A[A


preprocessing test:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1476/2000 [00:01<00:00, 1448.03it/s][A[A[A


preprocessing test:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1620/2000 [00:01<00:00, 1442.98it/s][A[A[A


preprocessing test:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1764/2000 [00:01<00:00, 1439.94it/s][A[A[A


preprocessing test:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1913/2000 [00:01<00:00, 1453.39it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1467.65it/s]
2019-09-26 19:43:05,645 - knowledge_transfer - INFO - test with geneo init
I0926 19:43:05.645699 140696480909056 knowledge_transfer.py:112] test with geneo init
2019-09-26 19:43:05,693 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:43:05.693781 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:43:05,717 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:43:05.717637 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:43:50,083 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:43:50.083382 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:43:50,083 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:43:50.083739 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00018: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [1, 7] 
conv2d_39
True
Model: "sequential_39"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_39 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_39 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_39 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_39 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00012: early stopping
Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_40 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_40 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_40 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_40 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 7.5902 - accuracy: 0.7987 - val_loss: 0.5189 - val_accuracy: 0.8803
Epoch 2/100
 - 3s - loss: 0.3253 - accuracy: 0.9210 - val_loss: 0.4009 - val_accuracy: 0.9100
Epoch 3/100
 - 4s - loss: 0.1639 - accuracy: 0.9526 - val_loss: 0.3907 - val_accuracy: 0.8973
Epoch 4/100
 - 3s - loss: 0.1103 - accuracy: 0.9620 - val_loss: 0.3315 - val_accuracy: 0.9227
Epoch 5/100
 - 3s - loss: 0.0744 - accuracy: 0.9749 - val_loss: 0.3488 - val_accuracy: 0.9220
Epoch 6/100
 - 4s - loss: 0.0438 - accuracy: 0.9836 - val_loss: 0.4017 - val_accuracy: 0.9147
Epoch 7/100
 - 3s - loss: 0.0221 - accuracy: 0.9914 - val_loss: 0.4121 - val_accuracy: 0.9137
Epoch 8/100
 - 3s - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.4022 - val_accuracy: 0.9143
Epoch 9/100
 - 3s - loss: 0.0222 - accuracy: 0.9906 - val_loss: 0.5889 - val_accuracy: 0.8977


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [04:00<02:13, 133.41s/it][A[A2019-09-26 19:44:24,538 - knowledge_transfer - INFO - Observer cifar10_11_cl_1_7.npy
I0926 19:44:24.538233 140696480909056 knowledge_transfer.py:94] Observer cifar10_11_cl_1_7.npy
2019-09-26 19:44:24,538 - knowledge_transfer - INFO - initialize data
I0926 19:44:24.538460 140696480909056 knowledge_transfer.py:104] initialize data



preprocessing train:   0%|          | 0/10000 [00:00<?, ?it/s][A[A[A


preprocessing train:   1%|          | 101/10000 [00:00<00:09, 1002.98it/s][A[A[A


preprocessing train:   2%|â–         | 210/10000 [00:00<00:09, 1026.67it/s][A[A[A


preprocessing train:   4%|â–Ž         | 360/10000 [00:00<00:08, 1133.98it/s][A[A[A


preprocessing train:   5%|â–Œ         | 519/10000 [00:00<00:07, 1240.70it/s][A[A[A


preprocessing train:   7%|â–‹         | 682/10000 [00:00<00:06, 1335.08it/s][A[A[A


preprocessing train:   8%|â–Š         | 841/10000 [00:00<00:06, 1401.80it/s][A[A[A


preprocessing train:  10%|â–ˆ         | 1001/10000 [00:00<00:06, 1454.71it/s][A[A[A


preprocessing train:  12%|â–ˆâ–        | 1153/10000 [00:00<00:06, 1471.67it/s][A[A[A


preprocessing train:  13%|â–ˆâ–Ž        | 1301/10000 [00:00<00:05, 1473.44it/s][A[A[A


preprocessing train:  15%|â–ˆâ–        | 1463/10000 [00:01<00:05, 1513.07it/s][A[A[A


preprocessing train:  16%|â–ˆâ–Œ        | 1624/10000 [00:01<00:05, 1539.95it/s][A[A[A


preprocessing train:  18%|â–ˆâ–Š        | 1807/10000 [00:01<00:05, 1615.65it/s][A[A[A


preprocessing train:  20%|â–ˆâ–‰        | 1983/10000 [00:01<00:04, 1655.68it/s][A[A[A


preprocessing train:  22%|â–ˆâ–ˆâ–       | 2150/10000 [00:01<00:04, 1640.54it/s][A[A[A


preprocessing train:  23%|â–ˆâ–ˆâ–Ž       | 2315/10000 [00:01<00:04, 1631.54it/s][A[A[A


preprocessing train:  25%|â–ˆâ–ˆâ–       | 2479/10000 [00:01<00:04, 1626.76it/s][A[A[A


preprocessing train:  26%|â–ˆâ–ˆâ–‹       | 2642/10000 [00:01<00:04, 1614.30it/s][A[A[A


preprocessing train:  28%|â–ˆâ–ˆâ–Š       | 2804/10000 [00:01<00:04, 1613.54it/s][A[A[A


preprocessing train:  30%|â–ˆâ–ˆâ–‰       | 2966/10000 [00:01<00:04, 1613.17it/s][A[A[A


preprocessing train:  31%|â–ˆâ–ˆâ–ˆâ–      | 3128/10000 [00:02<00:04, 1613.69it/s][A[A[A


preprocessing train:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3290/10000 [00:02<00:04, 1613.34it/s][A[A[A


preprocessing train:  35%|â–ˆâ–ˆâ–ˆâ–      | 3452/10000 [00:02<00:04, 1610.98it/s][A[A[A


preprocessing train:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3614/10000 [00:02<00:03, 1609.96it/s][A[A[A


preprocessing train:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3776/10000 [00:02<00:03, 1601.57it/s][A[A[A


preprocessing train:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3937/10000 [00:02<00:03, 1584.43it/s][A[A[A


preprocessing train:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4096/10000 [00:02<00:03, 1573.20it/s][A[A[A


preprocessing train:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4254/10000 [00:02<00:03, 1567.14it/s][A[A[A


preprocessing train:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4411/10000 [00:02<00:03, 1529.89it/s][A[A[A


preprocessing train:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4565/10000 [00:02<00:03, 1531.69it/s][A[A[A


preprocessing train:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4720/10000 [00:03<00:03, 1535.96it/s][A[A[A


preprocessing train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4876/10000 [00:03<00:03, 1541.04it/s][A[A[A


preprocessing train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5032/10000 [00:03<00:03, 1544.79it/s][A[A[A


preprocessing train:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5188/10000 [00:03<00:03, 1547.95it/s][A[A[A


preprocessing train:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5344/10000 [00:03<00:03, 1549.38it/s][A[A[A


preprocessing train:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5500/10000 [00:03<00:02, 1550.86it/s][A[A[A


preprocessing train:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5656/10000 [00:03<00:02, 1548.95it/s][A[A[A


preprocessing train:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5812/10000 [00:03<00:02, 1550.02it/s][A[A[A


preprocessing train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5970/10000 [00:03<00:02, 1556.03it/s][A[A[A


preprocessing train:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6126/10000 [00:03<00:02, 1556.68it/s][A[A[A


preprocessing train:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6282/10000 [00:04<00:02, 1555.81it/s][A[A[A


preprocessing train:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6438/10000 [00:04<00:02, 1552.34it/s][A[A[A


preprocessing train:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6594/10000 [00:04<00:02, 1550.33it/s][A[A[A


preprocessing train:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6750/10000 [00:04<00:02, 1547.78it/s][A[A[A


preprocessing train:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6906/10000 [00:04<00:01, 1549.07it/s][A[A[A


preprocessing train:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7062/10000 [00:04<00:01, 1550.71it/s][A[A[A


preprocessing train:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7218/10000 [00:04<00:01, 1550.82it/s][A[A[A


preprocessing train:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7374/10000 [00:04<00:01, 1549.74it/s][A[A[A


preprocessing train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7529/10000 [00:04<00:01, 1546.33it/s][A[A[A


preprocessing train:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7684/10000 [00:04<00:01, 1514.39it/s][A[A[A


preprocessing train:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7837/10000 [00:05<00:01, 1518.97it/s][A[A[A


preprocessing train:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7992/10000 [00:05<00:01, 1526.03it/s][A[A[A


preprocessing train:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8147/10000 [00:05<00:01, 1531.66it/s][A[A[A


preprocessing train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8302/10000 [00:05<00:01, 1536.92it/s][A[A[A


preprocessing train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8458/10000 [00:05<00:01, 1541.31it/s][A[A[A


preprocessing train:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8614/10000 [00:05<00:00, 1546.17it/s][A[A[A


preprocessing train:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8775/10000 [00:05<00:00, 1563.68it/s][A[A[A


preprocessing train:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8936/10000 [00:05<00:00, 1575.39it/s][A[A[A


preprocessing train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9098/10000 [00:05<00:00, 1586.49it/s][A[A[A


preprocessing train:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9259/10000 [00:05<00:00, 1592.97it/s][A[A[A


preprocessing train:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9420/10000 [00:06<00:00, 1596.51it/s][A[A[A


preprocessing train:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9582/10000 [00:06<00:00, 1603.15it/s][A[A[A


preprocessing train:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9743/10000 [00:06<00:00, 1601.78it/s][A[A[A


preprocessing train:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9904/10000 [00:06<00:00, 1592.23it/s][A[A[Apreprocessing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:06<00:00, 1556.84it/s]



preprocessing test:   0%|          | 0/2000 [00:00<?, ?it/s][A[A[A


preprocessing test:   8%|â–Š         | 159/2000 [00:00<00:01, 1588.24it/s][A[A[A


preprocessing test:  16%|â–ˆâ–Œ        | 321/2000 [00:00<00:01, 1597.49it/s][A[A[A


preprocessing test:  24%|â–ˆâ–ˆâ–       | 483/2000 [00:00<00:00, 1601.99it/s][A[A[A


preprocessing test:  32%|â–ˆâ–ˆâ–ˆâ–      | 645/2000 [00:00<00:00, 1604.94it/s][A[A[A


preprocessing test:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 791/2000 [00:00<00:00, 1555.87it/s][A[A[A


preprocessing test:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 945/2000 [00:00<00:00, 1548.82it/s][A[A[A


preprocessing test:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1104/2000 [00:00<00:00, 1559.36it/s][A[A[A


preprocessing test:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1261/2000 [00:00<00:00, 1561.99it/s][A[A[A


preprocessing test:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1420/2000 [00:00<00:00, 1569.69it/s][A[A[A


preprocessing test:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1580/2000 [00:01<00:00, 1576.01it/s][A[A[A


preprocessing test:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1738/2000 [00:01<00:00, 1576.64it/s][A[A[A


preprocessing test:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1897/2000 [00:01<00:00, 1579.99it/s][A[A[Apreprocessing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1576.47it/s]
2019-09-26 19:44:32,522 - knowledge_transfer - INFO - test with geneo init
I0926 19:44:32.522173 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:44:32,568 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:44:32.568436 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:44:32,590 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:44:32.590775 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:45:16,743 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:45:16.743771 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:45:16,744 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:45:16.744448 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00009: early stopping
Found 3 channels, this implementation only supports grayscale
-------------------------------------------------- Training on classes number [1, 7] 
conv2d_41
True
Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_41 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_41 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00012: early stopping
Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_42 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_42 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_42 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_42 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 5.5931 - accuracy: 0.7989 - val_loss: 0.3325 - val_accuracy: 0.8670
Epoch 2/100
 - 3s - loss: 0.2210 - accuracy: 0.9224 - val_loss: 0.2679 - val_accuracy: 0.9057
Epoch 3/100
 - 3s - loss: 0.1301 - accuracy: 0.9500 - val_loss: 0.3141 - val_accuracy: 0.9027
Epoch 4/100
 - 3s - loss: 0.1050 - accuracy: 0.9589 - val_loss: 0.3462 - val_accuracy: 0.8910
Epoch 5/100
 - 3s - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.3908 - val_accuracy: 0.8920
Epoch 6/100
 - 3s - loss: 0.0618 - accuracy: 0.9757 - val_loss: 0.3301 - val_accuracy: 0.9187
Epoch 7/100
 - 3s - loss: 0.0467 - accuracy: 0.9850 - val_loss: 0.3673 - val_accuracy: 0.9033
Epoch 8/100
 - 3s - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.3425 - val_accuracy: 0.9183
Epoch 9/100
 - 3s - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.3708 - val_accuracy: 0.9200
Epoch 10/100
 - 3s - loss: 0.0227 - accuracy: 0.9907 - val_loss: 0.4332 - val_accuracy: 0.9127
Epoch 11/100
 - 3s - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.4656 - val_accuracy: 0.9040
Epoch 12/100
 - 3s - loss: 0.0709 - accuracy: 0.9774 - val_loss: 0.4657 - val_accuracy: 0.9030
Epoch 13/100
 - 3s - loss: 0.0488 - accuracy: 0.9821 - val_loss: 0.4914 - val_accuracy: 0.9043
Epoch 14/100
 - 3s - loss: 0.0399 - accuracy: 0.9856 - val_loss: 0.5537 - val_accuracy: 0.9033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [05:44<00:00, 124.55s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [05:44<00:00, 114.76s/it]

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [05:44<11:28, 344.27s/it][A2019-09-26 19:46:08,420 - knowledge_transfer - INFO - Working on dataset ./train_all_data/750_ops_20exs fashion_mnist
I0926 19:46:08.420990 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/750_ops_20exs fashion_mnist


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:46:08,421 - knowledge_transfer - INFO - Observer fashion_mnist_11_cl_4_5.npy
I0926 19:46:08.421445 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_11_cl_4_5.npy
2019-09-26 19:46:08,421 - knowledge_transfer - INFO - data already initialised
I0926 19:46:08.421581 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:46:08,448 - knowledge_transfer - INFO - test with geneo init
I0926 19:46:08.448472 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:46:08,499 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:46:08.499085 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:46:08,522 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:46:08.522454 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:46:56,734 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:46:56.734531 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:46:56,734 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:46:56.734879 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00014: early stopping
conv2d_43
True
Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_43 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_43 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_43 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_43 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00013: early stopping
Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_44 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_44 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_44 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_44 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 3.3056 - accuracy: 0.8231 - val_loss: 0.2982 - val_accuracy: 0.8853
Epoch 2/100
 - 4s - loss: 0.1880 - accuracy: 0.9290 - val_loss: 0.3254 - val_accuracy: 0.8980
Epoch 3/100
 - 3s - loss: 0.1079 - accuracy: 0.9599 - val_loss: 0.3243 - val_accuracy: 0.9017
Epoch 4/100
 - 4s - loss: 0.0639 - accuracy: 0.9769 - val_loss: 0.2544 - val_accuracy: 0.9300
Epoch 5/100
 - 3s - loss: 0.0436 - accuracy: 0.9844 - val_loss: 0.2987 - val_accuracy: 0.9260
Epoch 6/100
 - 3s - loss: 0.0430 - accuracy: 0.9851 - val_loss: 0.4196 - val_accuracy: 0.9037
Epoch 7/100
 - 3s - loss: 0.0524 - accuracy: 0.9801 - val_loss: 0.3875 - val_accuracy: 0.9110
Epoch 8/100
 - 4s - loss: 0.0431 - accuracy: 0.9841 - val_loss: 0.3590 - val_accuracy: 0.9200
Epoch 9/100
 - 4s - loss: 0.0580 - accuracy: 0.9781 - val_loss: 0.3805 - val_accuracy: 0.9197


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:23<02:46, 83.14s/it][A[A2019-09-26 19:47:31,566 - knowledge_transfer - INFO - Observer fashion_mnist_7_cl_4_5.npy
I0926 19:47:31.566436 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_7_cl_4_5.npy
2019-09-26 19:47:31,566 - knowledge_transfer - INFO - data already initialised
I0926 19:47:31.566838 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:47:31,590 - knowledge_transfer - INFO - test with geneo init
I0926 19:47:31.590880 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:47:31,642 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:47:31.642874 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:47:31,667 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:47:31.667951 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:49:02,770 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:49:02.770737 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:49:02,771 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:49:02.771094 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00009: early stopping
conv2d_45
True
Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_45 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_45 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_45 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_45 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00025: early stopping
Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_46 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_46 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_46 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 5.1105 - accuracy: 0.7949 - val_loss: 0.5208 - val_accuracy: 0.8687
Epoch 2/100
 - 4s - loss: 0.2581 - accuracy: 0.9307 - val_loss: 0.3241 - val_accuracy: 0.9217
Epoch 3/100
 - 4s - loss: 0.1251 - accuracy: 0.9559 - val_loss: 0.3650 - val_accuracy: 0.9133
Epoch 4/100
 - 4s - loss: 0.0834 - accuracy: 0.9703 - val_loss: 0.3690 - val_accuracy: 0.9150
Epoch 5/100
 - 4s - loss: 0.0601 - accuracy: 0.9761 - val_loss: 0.3458 - val_accuracy: 0.9203
Epoch 6/100
 - 4s - loss: 0.0372 - accuracy: 0.9854 - val_loss: 0.3125 - val_accuracy: 0.9327
Epoch 7/100
 - 4s - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.3674 - val_accuracy: 0.9257
Epoch 8/100
 - 4s - loss: 0.0318 - accuracy: 0.9879 - val_loss: 0.4179 - val_accuracy: 0.9233
Epoch 9/100
 - 3s - loss: 0.0338 - accuracy: 0.9873 - val_loss: 0.5006 - val_accuracy: 0.9110
Epoch 10/100
 - 4s - loss: 0.0393 - accuracy: 0.9864 - val_loss: 0.4698 - val_accuracy: 0.9120
Epoch 11/100
 - 3s - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.4097 - val_accuracy: 0.9247


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [03:36<01:38, 98.27s/it][A[A2019-09-26 19:49:45,129 - knowledge_transfer - INFO - Observer fashion_mnist_21_cl_4_5.npy
I0926 19:49:45.129726 140696480909056 knowledge_transfer.py:94] Observer fashion_mnist_21_cl_4_5.npy
2019-09-26 19:49:45,129 - knowledge_transfer - INFO - data already initialised
I0926 19:49:45.129948 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:49:45,178 - knowledge_transfer - INFO - test with geneo init
I0926 19:49:45.178925 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:49:45,229 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:49:45.229548 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:49:45,253 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:49:45.253064 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:52:19,952 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:52:19.952203 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:52:19,952 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:52:19.952852 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00011: early stopping
conv2d_47
True
Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_47 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_47 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_47 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_47 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00038: early stopping
Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_48 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_48 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_48 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_48 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 2.0178 - accuracy: 0.7610 - val_loss: 0.4368 - val_accuracy: 0.8170
Epoch 2/100
 - 4s - loss: 0.4087 - accuracy: 0.8274 - val_loss: 0.4196 - val_accuracy: 0.8287
Epoch 3/100
 - 4s - loss: 0.3021 - accuracy: 0.8817 - val_loss: 0.3665 - val_accuracy: 0.8460
Epoch 4/100
 - 4s - loss: 0.2513 - accuracy: 0.9009 - val_loss: 0.3205 - val_accuracy: 0.8877
Epoch 5/100
 - 4s - loss: 0.2010 - accuracy: 0.9236 - val_loss: 0.3527 - val_accuracy: 0.8817
Epoch 6/100
 - 4s - loss: 0.2065 - accuracy: 0.9200 - val_loss: 0.3409 - val_accuracy: 0.8913
Epoch 7/100
 - 4s - loss: 0.1640 - accuracy: 0.9404 - val_loss: 0.3837 - val_accuracy: 0.8790
Epoch 8/100
 - 4s - loss: 0.1468 - accuracy: 0.9453 - val_loss: 0.3637 - val_accuracy: 0.8963
Epoch 9/100
 - 4s - loss: 0.1587 - accuracy: 0.9381 - val_loss: 0.3939 - val_accuracy: 0.8830
Epoch 10/100
 - 4s - loss: 0.1018 - accuracy: 0.9610 - val_loss: 0.4238 - val_accuracy: 0.8787
Epoch 11/100
 - 4s - loss: 0.1051 - accuracy: 0.9630 - val_loss: 0.4452 - val_accuracy: 0.8887
Epoch 12/100
 - 4s - loss: 0.1146 - accuracy: 0.9597 - val_loss: 0.6877 - val_accuracy: 0.8737
Epoch 13/100
 - 4s - loss: 0.1061 - accuracy: 0.9601 - val_loss: 0.4759 - val_accuracy: 0.8960


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [07:05<00:00, 131.38s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [07:05<00:00, 141.78s/it]

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [12:49<06:08, 368.60s/it][A2019-09-26 19:53:13,775 - knowledge_transfer - INFO - Working on dataset ./train_all_data/750_ops_20exs mnist
I0926 19:53:13.775311 140696480909056 knowledge_transfer.py:91] Working on dataset ./train_all_data/750_ops_20exs mnist


  0%|          | 0/3 [00:00<?, ?it/s][A[A2019-09-26 19:53:13,775 - knowledge_transfer - INFO - Observer mnist_7_cl_5_7.npy
I0926 19:53:13.775800 140696480909056 knowledge_transfer.py:94] Observer mnist_7_cl_5_7.npy
2019-09-26 19:53:13,775 - knowledge_transfer - INFO - data already initialised
I0926 19:53:13.775935 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:53:13,798 - knowledge_transfer - INFO - test with geneo init
I0926 19:53:13.798859 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:53:13,850 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:53:13.850212 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:53:13,873 - knowledge_transfer - INFO - from intializer (7, 7, 1, 64)
I0926 19:53:13.873790 140696480909056 knowledge_transfer.py:44] from intializer (7, 7, 1, 64)
2019-09-26 19:54:13,307 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:54:13.307430 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:54:13,307 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:54:13.307720 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00013: early stopping
conv2d_49
True
Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_49 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_49 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_49 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_49 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Epoch 00016: early stopping
Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_50 (Conv2D)           (None, 122, 122, 64)      3200      
_________________________________________________________________
max_pooling2d_50 (MaxPooling (None, 61, 61, 64)        0         
_________________________________________________________________
flatten_50 (Flatten)         (None, 238144)            0         
_________________________________________________________________
dense_50 (Dense)             (None, 2)                 476290    
=================================================================
Total params: 479,490
Trainable params: 479,490
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 11.9514 - accuracy: 0.7809 - val_loss: 1.0561 - val_accuracy: 0.8870
Epoch 2/100
 - 4s - loss: 0.6253 - accuracy: 0.9067 - val_loss: 0.7624 - val_accuracy: 0.8867
Epoch 3/100
 - 4s - loss: 0.3583 - accuracy: 0.9306 - val_loss: 0.4952 - val_accuracy: 0.9087
Epoch 4/100
 - 3s - loss: 0.1237 - accuracy: 0.9653 - val_loss: 0.3686 - val_accuracy: 0.9257
Epoch 5/100
 - 4s - loss: 0.0618 - accuracy: 0.9783 - val_loss: 0.3643 - val_accuracy: 0.9267
Epoch 6/100
 - 3s - loss: 0.0425 - accuracy: 0.9826 - val_loss: 0.3745 - val_accuracy: 0.9317
Epoch 7/100
 - 3s - loss: 0.0217 - accuracy: 0.9913 - val_loss: 0.3666 - val_accuracy: 0.9300
Epoch 8/100
 - 4s - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.3934 - val_accuracy: 0.9300
Epoch 9/100
 - 4s - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.5754 - val_accuracy: 0.9053
Epoch 10/100
 - 4s - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.4306 - val_accuracy: 0.9263
Epoch 11/100
 - 3s - loss: 0.0643 - accuracy: 0.9799 - val_loss: 0.5125 - val_accuracy: 0.9167


 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [01:41<03:23, 101.96s/it][A[A2019-09-26 19:54:55,732 - knowledge_transfer - INFO - Observer mnist_21_cl_5_7.npy
I0926 19:54:55.732481 140696480909056 knowledge_transfer.py:94] Observer mnist_21_cl_5_7.npy
2019-09-26 19:54:55,732 - knowledge_transfer - INFO - data already initialised
I0926 19:54:55.732702 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:54:55,781 - knowledge_transfer - INFO - test with geneo init
I0926 19:54:55.781446 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:54:55,831 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:54:55.831929 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:54:55,855 - knowledge_transfer - INFO - from intializer (21, 21, 1, 64)
I0926 19:54:55.855567 140696480909056 knowledge_transfer.py:44] from intializer (21, 21, 1, 64)
2019-09-26 19:56:38,753 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:56:38.753693 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:56:38,754 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:56:38.754285 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00011: early stopping
conv2d_51
True
Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_51 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_51 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_51 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Epoch 00025: early stopping
Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_52 (Conv2D)           (None, 108, 108, 64)      28288     
_________________________________________________________________
max_pooling2d_52 (MaxPooling (None, 54, 54, 64)        0         
_________________________________________________________________
flatten_52 (Flatten)         (None, 186624)            0         
_________________________________________________________________
dense_52 (Dense)             (None, 2)                 373250    
=================================================================
Total params: 401,538
Trainable params: 401,538
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 1.3412 - accuracy: 0.7854 - val_loss: 0.4821 - val_accuracy: 0.7950
Epoch 2/100
 - 4s - loss: 0.3384 - accuracy: 0.8640 - val_loss: 0.4089 - val_accuracy: 0.8477
Epoch 3/100
 - 4s - loss: 0.2831 - accuracy: 0.8873 - val_loss: 0.4268 - val_accuracy: 0.8480
Epoch 4/100
 - 4s - loss: 0.2601 - accuracy: 0.8991 - val_loss: 0.3715 - val_accuracy: 0.8660
Epoch 5/100
 - 4s - loss: 0.2262 - accuracy: 0.9141 - val_loss: 0.5264 - val_accuracy: 0.8610
Epoch 6/100
 - 4s - loss: 0.1912 - accuracy: 0.9291 - val_loss: 0.3842 - val_accuracy: 0.8670
Epoch 7/100
 - 4s - loss: 0.1604 - accuracy: 0.9393 - val_loss: 0.4430 - val_accuracy: 0.8823
Epoch 8/100
 - 4s - loss: 0.1533 - accuracy: 0.9446 - val_loss: 0.4085 - val_accuracy: 0.8837
Epoch 9/100
 - 4s - loss: 0.1607 - accuracy: 0.9426 - val_loss: 0.4864 - val_accuracy: 0.8637
Epoch 10/100
 - 4s - loss: 0.1336 - accuracy: 0.9484 - val_loss: 0.4890 - val_accuracy: 0.8830
Epoch 11/100
 - 4s - loss: 0.1023 - accuracy: 0.9640 - val_loss: 0.5427 - val_accuracy: 0.8867
Epoch 12/100
 - 4s - loss: 0.0893 - accuracy: 0.9670 - val_loss: 0.8270 - val_accuracy: 0.8767
Epoch 13/100
 - 4s - loss: 0.1099 - accuracy: 0.9621 - val_loss: 0.6887 - val_accuracy: 0.8953
Epoch 14/100
 - 4s - loss: 0.1480 - accuracy: 0.9506 - val_loss: 0.6387 - val_accuracy: 0.8840
Epoch 15/100
 - 4s - loss: 0.0868 - accuracy: 0.9699 - val_loss: 0.7421 - val_accuracy: 0.8730
Epoch 16/100
 - 4s - loss: 0.0871 - accuracy: 0.9696 - val_loss: 0.6828 - val_accuracy: 0.8877
Epoch 17/100
 - 4s - loss: 0.0964 - accuracy: 0.9670 - val_loss: 0.7882 - val_accuracy: 0.8680
Epoch 18/100
 - 4s - loss: 0.0943 - accuracy: 0.9696 - val_loss: 0.7611 - val_accuracy: 0.8710


 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [04:39<02:04, 124.72s/it][A[A2019-09-26 19:57:53,560 - knowledge_transfer - INFO - Observer mnist_11_cl_5_7.npy
I0926 19:57:53.560022 140696480909056 knowledge_transfer.py:94] Observer mnist_11_cl_5_7.npy
2019-09-26 19:57:53,560 - knowledge_transfer - INFO - data already initialised
I0926 19:57:53.560244 140696480909056 knowledge_transfer.py:110] data already initialised
2019-09-26 19:57:53,589 - knowledge_transfer - INFO - test with geneo init
I0926 19:57:53.589292 140696480909056 knowledge_transfer.py:112] test with geneo init
knowledge_transfer.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, axes = plt.subplots(2,2)
2019-09-26 19:57:53,640 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:57:53.640603 140696480909056 knowledge_transfer.py:147] input_shape (128, 128, 1)
2019-09-26 19:57:53,664 - knowledge_transfer - INFO - from intializer (11, 11, 1, 64)
I0926 19:57:53.664326 140696480909056 knowledge_transfer.py:44] from intializer (11, 11, 1, 64)
2019-09-26 19:58:42,887 - knowledge_transfer - INFO - glorot uniform initialization
I0926 19:58:42.887219 140696480909056 knowledge_transfer.py:165] glorot uniform initialization
2019-09-26 19:58:42,887 - knowledge_transfer - INFO - input_shape (128, 128, 1)
I0926 19:58:42.887513 140696480909056 knowledge_transfer.py:191] input_shape (128, 128, 1)
Epoch 00018: early stopping
conv2d_53
True
Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_53 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_53 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_53 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_53 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Epoch 00013: early stopping
Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_54 (Conv2D)           (None, 118, 118, 64)      7808      
_________________________________________________________________
max_pooling2d_54 (MaxPooling (None, 59, 59, 64)        0         
_________________________________________________________________
flatten_54 (Flatten)         (None, 222784)            0         
_________________________________________________________________
dense_54 (Dense)             (None, 2)                 445570    
=================================================================
Total params: 453,378
Trainable params: 453,378
Non-trainable params: 0
_________________________________________________________________
Train on 7000 samples, validate on 3000 samples
Epoch 1/100
 - 4s - loss: 8.3306 - accuracy: 0.8069 - val_loss: 0.3021 - val_accuracy: 0.8893
Epoch 2/100
 - 4s - loss: 0.2109 - accuracy: 0.9241 - val_loss: 0.2940 - val_accuracy: 0.8997
Epoch 3/100
 - 4s - loss: 0.1262 - accuracy: 0.9493 - val_loss: 0.3276 - val_accuracy: 0.8900
Epoch 4/100
 - 3s - loss: 0.0809 - accuracy: 0.9686 - val_loss: 0.2662 - val_accuracy: 0.9180
Epoch 5/100
 - 4s - loss: 0.0494 - accuracy: 0.9821 - val_loss: 0.2671 - val_accuracy: 0.9320
Epoch 6/100
 - 4s - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.3215 - val_accuracy: 0.9080
Epoch 7/100
 - 3s - loss: 0.0373 - accuracy: 0.9851 - val_loss: 0.2825 - val_accuracy: 0.9280
Epoch 8/100
 - 3s - loss: 0.0538 - accuracy: 0.9780 - val_loss: 0.3781 - val_accuracy: 0.9053
Epoch 9/100
 - 3s - loss: 0.0547 - accuracy: 0.9783 - val_loss: 0.3458 - val_accuracy: 0.9233
Epoch 10/100
 - 3s - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.4392 - val_accuracy: 0.9077


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [06:08<00:00, 113.90s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [06:08<00:00, 122.81s/it]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [18:58<00:00, 368.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [18:58<00:00, 379.35s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [41:00<00:00, 859.48s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [41:00<00:00, 820.10s/it]
Epoch 00010: early stopping
